{"pages":[],"posts":[{"title":"epoll理论解读","text":"I/O的操作 首先我们来定义流的概念，一个流可以是文件，socket，pipe等等可以进行I/O操作的内核对象。 不管是文件，还是套接字，还是管道，我们都可以把他们看作流。 之后我们来讨论I/O的操作，通过read，我们可以从流中读入数据；通过write，我们可以往流写入数据。现在假定一个情形，我们需要从流中读数据，但是流中还没有数据，（典型的例子为，客户端要从socket读如数据，但是服务器还没有把数据传回来），这时候该怎么办？ 阻塞非阻塞阻塞I/O模式阻塞I/O模式下，一个线程只能处理一个流的I/O事件。如果想要同时处理多个流，要么多进程(fork)，要么多线程(pthread_create)，很不幸这两种方法效率都不高。 非阻塞忙轮询的I/O 于是再来考虑非阻塞忙轮询的I/O方式，我们发现我们可以同时处理多个流了（把一个流从阻塞模式切换到非阻塞模式再此不予讨论）： while true { for i in stream[]; { if i has data read until unavailable } } 我们只要不停的把所有流从头到尾问一遍，又从头开始。这样就可以处理多个流了，但这样的做法显然不好，因为如果所有的流都没有数据，那么只会白白浪费CPU。这里要补充一点，阻塞模式下，内核对于I/O事件的处理是阻塞或者唤醒，而非阻塞模式下则把I/O事件交给其他对象（后文介绍的select以及epoll）处理甚至直接忽略。 select 为了避免CPU空转，可以引进了一个代理（一开始有一位叫做select的代理，后来又有一位叫做poll的代理，不过两者的本质是一样的）。这个代理比较厉害，可以同时观察许多流的I/O事件，在空闲的时候，会把当前线程阻塞掉，当有一个或多个流有I/O事件时，就从阻塞态中醒来，于是我们的程序就会轮询一遍所有的流（于是我们可以把“忙”字去掉了）。代码长这样: while true { select(streams[]) for i in streams[] { if i has data read until unavailable } } 于是，如果没有I/O事件产生，我们的程序就会阻塞在select处。但是依然有个问题，我们从select那里仅仅知道了，有I/O事件发生了，但却并不知道是那几个流（可能有一个，多个，甚至全部），我们只能无差别轮询所有流，找出能读出数据，或者写入数据的流，对他们进行操作。 但是使用select，我们有O(n)的无差别轮询复杂度，同时处理的流越多，没一次无差别轮询时间就越长。再次 说了这么多，终于能好好解释epoll了 epoll epoll可以理解为event poll，不同于忙轮询和无差别轮询，epoll之会把哪个流发生了怎样的I/O事件通知我们。此时我们对这些流的操作都是有意义的。（复杂度降低到了O(1)） 在讨论epoll的实现细节之前，先把epoll的相关操作列出： epoll_create 创建一个epoll对象，一般epollfd = epoll_create() epoll_ctl （epoll_add/epoll_del的合体），往epoll对象中增加/删除某一个流的某一个事件 比如 epoll_ctl(epollfd, EPOLL_CTL_ADD, socket, EPOLLIN);//注册缓冲区非空事件，即有数据流入 epoll_ctl(epollfd, EPOLL_CTL_DEL, socket, EPOLLOUT);//注册缓冲区非满事件，即流可以被写入 epoll_wait(epollfd,…)等待直到注册的事件发生 （注：当对一个非阻塞流的读写发生缓冲区满或缓冲区空，write/read会返回-1，并设置errno=EAGAIN。而epoll只关心缓冲区非满和缓冲区非空事件）。 一个epoll模式的代码大概的样子是： while true { active_stream[] = epoll_wait(epollfd) for i in active_stream[] { read or write till } } 参照： 通俗解读：https://blog.csdn.net/u011671986/article/details/79449853 详细解读：https://bbs.gameres.com/thread_842984_1_1.html","link":"/2019/11/25/epoll/"},{"title":"Hello World","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new \"My New Post\" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","link":"/2019/11/14/hello-world/"},{"title":"I/O模型(同步，异步，阻塞，非阻塞)","text":"思考：​ 同步（synchronous） IO和异步（asynchronous） IO，阻塞（blocking） IO和非阻塞（non-blocking）IO分别是什么，到底有什么区别？ ​ 用户进程，系统进程注意区分 IO发生时涉及的对象和步骤​ 对于一个network IO (这里我们以read举例)，它会涉及到两个系统对象，一个是调用这个IO的process (or thread)，另一个就是系统内核(kernel)。当一个read操作发生时，它会经历两个阶段： 等待数据准备 (Waiting for the data to be ready) 将数据从内核拷贝到进程中 (Copying the data from the kernel to the proces) 记住这两点很重要，因为这些IO Model的区别就是在两个阶段上各有不同的情况。 Stevens在文章中一共比较了五种IO Model blocking IO(阻塞) nonblocking IO(非阻塞) IO multiplexing（多路复用） signal driven IO（信号驱动） asynchronous IO（异步） blocking IO ​ 当用户进程调用了recvfrom这个系统调用，kernel就开始了IO的第一个阶段：准备数据。对于network io来说，很多时候数据在一开始还没有到达（比如，还没有收到一个完整的UDP包），这个时候kernel就要等待足够的数据到来。而在用户进程这边，整个进程会被阻塞。当kernel一直等到数据准备好了，它就会将数据从kernel中拷贝到用户内存，然后kernel返回结果，用户进程才解除block的状态，重新运行起来。所以，blocking IO的特点就是在IO执行的两个阶段都被block了。 non-blocking IO ​ 当用户进程发出read操作时，如果kernel中的数据还没有准备好，那么它并不会block用户进程，而是立刻返回一个error。从用户进程角度讲 ，它发起一个read操作后，并不需要等待，而是马上就得到了一个结果。用户进程判断结果是一个error时，它就知道数据还没有准备好，于是它可以再次发送read操作。一旦kernel中的数据准备好了，并且又再次收到了用户进程的system call，那么它马上就将数据拷贝到了用户内存，然后返回。所以，用户进程其实是需要不断的主动询问kernel数据好了没有。 IO multiplexing​ IO multiplexing这个词可能有点陌生，但是如果我说select，epoll，大概就都能明白了。有些地方也称这种IO方式为event driven IO。我们都知道，select/epoll的好处就在于单个process就可以同时处理多个网络连接的IO。它的基本原理就是select/epoll这个function会不断的轮询所负责的所有socket，当某个socket有数据到达了，就通知用户进程。它的流程如图： ​ 当用户进程调用了select，那么整个进程会被block，而同时，kernel会“监视”所有select负责的socket，当任何一个socket中的数据准备好了，select就会返回。这个时候用户进程再调用read操作，将数据从kernel拷贝到用户进程。 这个图和阻塞IO的图其实并没有太大的不同，事实上，还更差一些。因为这里需要使用两个system call (select 和 recvfrom)，而blocking IO只调用了一个system call (recvfrom)。但是，用select的优势在于它可以同时处理多个connection。（所以，如果处理的连接数不是很高的话，使用select/epoll的web server不一定比使用multi-threading + blocking IO的web server性能更好，可能延迟还更大。select/epoll的优势并不是对于单个连接能处理得更快，而是在于能处理更多的连接。）​ 在IO multiplexing Model中，实际中，对于每一个socket，一般都设置成为non-blocking，但是，如上图所示，整个用户的进程其实是一直被block的。只不过进程是被select这个函数block，而不是被socket IO给block。​ signal driven IO Asynchronous I/O​ 这类函数的工作机制是告知内核启动某个操作，并让内核在整个操作（包括将数据从内核拷贝到用户空间）完成后通知我们。 ​ 用户进程发起read操作之后，立刻就可以开始去做其它的事。而另一方面，从kernel的角度，当它受到一个asynchronous read之后，首先它会立刻返回，所以不会对用户进程产生任何block。然后，kernel会等待数据准备完成，然后将数据拷贝到用户内存，当这一切都完成之后，kernel会给用户进程发送一个signal，告诉它read操作完成了。 QAblocking和non-blocking的区别​ 调用blocking IO会一直block住对应的进程直到操作完成，而non-blocking IO在kernel还准备数据的情况下会立刻返回。 synchronous IO和asynchronous IO的区别​ Stevens给出的定义（其实是POSIX的定义）是这样子的：​ A synchronous I/O operation causes the requesting process to be blocked until that I/O operation completes;​ An asynchronous I/O operation does not cause the requesting process to be blocked; ​ 两者的区别就在于synchronous IO做”IO operation”的时候会将process阻塞。按照这个定义，之前所述的blocking IO，non-blocking IO，IO multiplexing都属于synchronous IO。 ​ 定义中所指的”IO operation”是指真实的IO操作，就是例子中的recvfrom这个system call。 non-blocking IO和asynchronous IO的区别​ 区别在于非阻塞在第一个阶段check第二阶段block，异步全程交给kenel处理 参照https://blog.csdn.net/historyasamirror/article/details/5778378 Richard Stevens的“UNIX® Network Programming Volume 1, Third Edition: The Sockets Networking ”，6.2节“I/O Models ”","link":"/2019/11/25/io-learning/"},{"title":"linux内存swap","text":"什么是linux的内存机制​ 我们知道，直接从物理内存读写数据要比从硬盘读写数据要快的多，因此，我们希望所有数据的读取和写入都在内存完成，而内存是有限的，这样就引出了物理内存与虚拟内存的概念。 ​ 物理内存就是系统硬件提供的内存大小，是真正的内存，相对于物理内存，在linux下还有一个虚拟内存的概念，虚拟内存就是为了满足物理内存的不足而提出的策略，它是利用磁盘空间虚拟出的一块逻辑内存，用作虚拟内存的磁盘空间被称为交换空间（Swap Space）。 ​ 作为物理内存的扩展，linux会在物理内存不足时，使用交换分区的虚拟内存，更详细的说，就是内核会将暂时不用的内存块信息写到交换空间，这样以来，物理内存得到了释放，这块内存就可以用于其它目的，当需要用到原始的内容时，这些信息会被重新从交换空间读入物理内存。 ​ Linux的内存管理采取的是分页存取机制，为了保证物理内存能得到充分的利用，内核会在适当的时候将物理内存中不经常使用的数据块自动交换到虚拟内存中，而将经常使用的信息保留到物理内存。 ​ 要深入了解linux内存运行机制，需要知道下面提到的几个方面： Linux系统会不时的进行页面交换操作，以保持尽可能多的空闲物理内存，即使并没有什么事情需要内存，Linux也会交换出暂时不用的内存页面。这可以避免等待交换所需的时间。 Linux 进行页面交换是有条件的，不是所有页面在不用时都交换到虚拟内存，linux内核根据”最近最经常使用“算法，仅仅将一些不经常使用的页面文件交换到虚拟 内存，有时我们会看到这么一个现象：linux物理内存还有很多，但是交换空间也使用了很多。其实，这并不奇怪，例如，一个占用很大内存的进程运行时，需 要耗费很多内存资源，此时就会有一些不常用页面文件被交换到虚拟内存中，但后来这个占用很多内存资源的进程结束并释放了很多内存时，刚才被交换出去的页面 文件并不会自动的交换进物理内存，除非有这个必要，那么此刻系统物理内存就会空闲很多，同时交换空间也在被使用，就出现了刚才所说的现象了。关于这点，不 用担心什么，只要知道是怎么一回事就可以了。 交换空间的页面在使用时会首先被交换到物理内存，如果此时没有足够的物理内存来容纳这些页 面，它们又会被马上交换出去，如此以来，虚拟内存中可能没有足够空间来存储这些交换页面，最终会导致linux出现假死机、服务异常等问题，linux虽 然可以在一段时间内自行恢复，但是恢复后的系统已经基本不可用了。 因此，合理规划和设计Linux内存的使用，是非常重要的. ​ 在Linux 操作系统中，当应用程序需要读取文件中的数据时，操作系统先分配一些内存，将数据从磁盘读入到这些内存中，然后再将数据分发给应用程序；当需要往文件中写 数据时，操作系统先分配内存接收用户数据，然后再将数据从内存写到磁盘上。然而，如果有大量数据需要从磁盘读取到内存或者由内存写入磁盘时，系统的读写性 能就变得非常低下，因为无论是从磁盘读数据，还是写数据到磁盘，都是一个很消耗时间和资源的过程，在这种情况下，Linux引入了buffers和 cached机制。 ​ buffers与cached都是内存操作，用来保存系统曾经打开过的文件以及文件属性信息，这样当操作系统需要读取某些文件时，会首先在buffers 与cached内存区查找，如果找到，直接读出传送给应用程序，如果没有找到需要数据，才从磁盘读取，这就是操作系统的缓存机制，通过缓存，大大提高了操 作系统的性能。但buffers与cached缓冲的内容却是不同的。 ​ buffers是用来缓冲块设备做的，它只记录文件系统的元数据（metadata）以及 tracking in-flight pages，而cached是用来给文件做缓冲。更通俗一点说：buffers主要用来存放目录里面有什么内容，文件的属性以及权限等等。 创建SWAP内存1234567891011创建2G的空间dd if=/dev/zero of=/root/swapfile1 bs=1M count=2048创建swap分区mkswap /root/swapfile1开启虚拟内存chmod 0600 /root/swapfile1swapon /root/swapfile1设定虚拟内存开机自动挂载echo &quot;/root/swapfile1 swap swapdefaults 0 0&quot; &gt;&gt; /etc/fstab查看虚拟内存信息free -m或者swapon -s以及ll -h 和df -h 取消SWAP内存123456取消 SWAP文件swapoff /root/swapfile1取消开机启动加载sed -i &quot;/swapfile1/d&quot; /etc/fstab删除 SWAP文件rm -rf /root/swapfile1","link":"/2019/11/14/linux%E5%86%85%E5%AD%98swap/"},{"title":"reactor和preactor模型","text":"Reactor模型Reactor的核心思想： 将关注的I/O事件注册到多路复用器上，一旦有I/O事件触发，将事件分发到事件处理器中，执行就绪I/O事件对应的处理函数中。模型中有三个重要的组件： 多路复用器：由操作系统提供接口，Linux提供的I/O复用接口有select、poll、epoll； 事件分离器：将多路复用器返回的就绪事件分发到事件处理器中； 事件处理器：处理就绪事件处理函数。 Handle：标示文件描述符； Event Demultiplexer：执行多路事件分解操作，对操作系统内核实现I/O复用接口的封装；用于阻塞等待发生在句柄集合上的一个或多个事件（如select/poll/epoll）； Event Handler：事件处理接口； Event Handler A(B)：实现应用程序所提供的特定事件处理逻辑； Reactor：反应器，定义一个接口，实现以下功能： a)供应用程序注册和删除关注的事件句柄； b)运行事件处理循环； c)等待的就绪事件触发，分发事件到之前注册的回调函数上处理. 经典Reactor模式 在经典Reactor模式中，包含以下角色： Reactor ：将I/O事件发派给对应的Handler Acceptor ：处理客户端连接请求 Handlers ：执行非阻塞读/写 多工作线程Reactor模式 多Reactor的Reactor模式 Proactor模型​ 与Reactor不同的是，Proactor使用异步I/O系统接口将I/O操作托管给操作系统，Proactor模型中分发处理异步I/O完成事件，并调用相应的事件处理接口来处理业务逻辑。 Proactor类结构中包含有如下角色： Handle：用来标识socket连接或是打开文件； Async Operation Processor：异步操作处理器；负责执行异步操作，一般由操作系统内核实现； Async Operation：异步操作； Completion Event Queue：完成事件队列；异步操作完成的结果放到队列中等待后续使用； Proactor：主动器；为应用程序进程提供事件循环；从完成事件队列中取出异步操作的结果，分发调用相应的后续处理逻辑； Completion Handler：完成事件接口；一般是由回调函数组成的接口； Completion Handler A(B)：完成事件处理逻辑；实现接口定义特定的应用处理逻辑。 支持情况​ windows对异步I/O提供了非常好的支持，常用Proactor的模型实现服务器；而Linux对异步I/O操作(aio接口)的支持并不是特别理想，而且不能直接处理accept，因此Linux平台上还是以Reactor模型为主。 ​ 目前实现了纯异步操作的操作系统少，实现优秀的如windows IOCP，但由于其windows系统用于服务器的局限性，目前应用范围较小；而Unix/Linux系统对纯异步的支持有限，应用事件驱动的主流还是通过select/epoll来实现； java提供Asynchronous I/O相关接口以支持异步I/O，AIO有两种api进行操作： Future 方式 即提交一个 I/O 操作请求，返回一个 Future。然后您可以对 Future 进行检查，确定它是否完成，或者阻塞 IO 操作直到操作正常完成或者超时异常。 Callback 方式 即提交一个 I/O 操作请求，并且指定一个 CompletionHandler。当异步 I/O 操作完成时，便发送一个通知，此时这个 CompletionHandler 对象的 completed 或者 failed 方法将会被调用。 参照： https://www.jianshu.com/p/b4de9b85c79d","link":"/2019/11/25/reactor/"},{"title":"redis学习（三）","text":"缓存的击穿 穿透 和 雪崩缓存雪崩​ 缓存雪崩是指在我们设置缓存时采用了相同的过期时间，导致缓存在某一时刻同时失效，请求全部转发到，瞬时压力过重雪崩。或在大部分数据都没缓存的时候被一次性同时访问。 解决方案： 缓存失效时的雪崩效应对底层系统的冲击非常可怕。我们可以用以下方式来避免： 1.数据预热： 可以通过缓存reload机制，预先去更新缓存，再即将发生大并发访问前手动触发加载缓存不同的key，设置不同的过期时间，让缓存失效的时间点尽量均匀 2.做二级缓存，或者双缓存策略：A1为原始缓存，A2为拷贝缓存，A1失效时，可以访问A2，A1缓存失效时间设置为短期，A2设置为长期。 3.缓存永远不过期： 这里的“永远不过期”包含两层意思： 1)从缓存上看，确实没有设置过期时间，这就保证了，不会出现热点key过期问题，也就是“物理”不过期。 2)从功能上看，如果不过期，那不就成静态的了吗？所以我们把过期时间存在key对应的里，如果发现要过期了，通过一个后台的异步线程进行缓存的构建，也就是“逻辑”过期. 缓存击穿​ 对于一些设置了过期时间的key，如果这些key可能会在某些时间点被超高并发地访问，是一种非常“热点”的数据，这个时候，需要考虑一个问题：缓存被“击穿”的问题。 ​ 这个和缓存雪崩的区别在于这里针对某一key缓存，前者则是很多key。缓存在某个时间点过期的时候，恰好在这个时间点对这个Key有大量的并发请求过来，这些请求发现缓存过期一般都会从后端DB加载数据并回设到缓存，这个时候大并发的请求可能会瞬间把后端DB压垮。 解决方案： 使用互斥锁(mutex key) 业界比较常用的做法，是使用mutex。简单地来说，就是在缓存失效的时候（判断拿出来的值为空），不是立即去load db，而是先使用缓存工具的某些带成功操作返回值的操作（比如mutex key，当操作返回成功时，再进行Redis的SETNX或者Memcache的ADD）去set一个的操作并回设缓存；否则，就重试整个get缓存的方法。 缓存穿透​ 缓存穿透是指查询一个一定不存在的数据，由于缓存是不命中时被动写的，并且出于容错考虑，如果从存储层查不到数据则不写入缓存，这将导致这个不存在的数据每次请求都要到存储层去查询，失去了缓存的意义。在流量大时，可能DB就挂掉了，要是有人利用不存在的key频繁攻击我们的应用，这就是漏洞。 解决方案： 有很多种方法可以有效地解决缓存穿透问题， ​ 1.最常见的则是采用布隆过滤器，将所有可能存在的数据哈希到一个足够大的bitmap中，一个一定不存在的数据会被这个bitmap拦截掉，从而避免了对底层存储系统的查询压力。 ​ 2.另外也有一个更为简单粗暴的方法，如果一个查询返回的数据为空（不管是数据不存在，还是系统故障），我们仍然把这个空结果进行缓存，但它的过期时间会很短，最长不超过五分钟。","link":"/2019/11/26/redis-learning-3/"},{"title":"redis学习（一）","text":"简介REmote DIctionary Server(Redis) 是一个由SalvatoreSanfilippo写的key-value存储系统。 Redis是一个开源的使用ANSI C语言编写、遵守BSD协议、支持网络、可基于内存亦可持久化的日志型、Key-Value数据库，并提供多种语言的API。 它通常被称为数据结构服务器，因为值（value）可以是字符串(String), 哈希(Map), 列表(list), 集合(sets) 和有序集合(sorted sets)等类型。 Redis 与其他 key - value 缓存产品有以下三个特点： Redis支持数据的持久化，可以将内存中的数据保持在磁盘中，重启的时候可以再次加载进行使用。 Redis不仅仅支持简单的key-value类型的数据，同时还提供list，set，zset，hash等数据结构的存储。 Redis支持数据的备份，即master-slave模式的数据备份。 redis数据类型 String Hash List Set Sorted set redis常用命令 Key（键） String Hash List Set Sorted set pub/sub（发布／订阅） Transactions（事物） Script（脚本） Conection（链接） Server（服务器） 后面五个不常用，具体命令操作参见地址： 官方 翻译 redis持久化（RDB／AOF） RDB 持久化可以在指定的时间间隔内生成数据集的时间点快照（point-in-time snapshot）。 AOF 持久化记录服务器执行的所有写操作命令，并在服务器启动时，通过重新执行这些命令来还原数据集。 AOF 文件中的命令全部以 Redis 协议的格式来保存，新命令会被追加到文件的末尾。 Redis 还可以在后台对 AOF 文件进行重写（rewrite），使得 AOF 文件的体积不会超出保存数据集状态所需的实际大小。 Redis 还可以同时使用 AOF 持久化和 RDB 持久化。 在这种情况下， 当 Redis 重启时， 它会优先使用 AOF 文件来还原数据集， 因为 AOF 文件保存的数据集通常比 RDB 文件所保存的数据集更完整。 你甚至可以关闭持久化功能，让数据只在服务器运行时存在。 缺点： RDB： 1.设置不同的保存点（save point）来控制保存 RDB 文件的频率，一旦发生故障可能会丢失数据。 2.每次保存 RDB 的时候，Redis 都要 fork() 出一个子进程，并由子进程来进行实际的持久化工作。 在数据集比较庞大时， fork() 可能会非常耗时，造成服务器在某某毫秒内停止处理客户端； AOF： 1.相同的数据集来说，AOF 文件的体积通常要大于 RDB 文件的体积。 2…. 优点： RDB： 1.保存了 Redis 在某个时间点上的数据集。 这种文件非常适合用于进行备份 2.速度快，无论保存还是恢复 AOF： 1.非常耐久（much more durable） 2.AOF 文件是一个只进行追加操作的日志文件（append only log）， 因此对 AOF 文件的写入不需要进行 seek 3.在 AOF 文件体积变得过大时，自动地在后台对 AOF 进行重写： 重写后的新 AOF 文件包含了恢复当前数据集所需的最小命令集合。 4.AOF 文件有序地保存了对数据库执行的所有写入操作， 这些写入操作以 Redis 协议的格式保存， 因此 AOF 文件的内容非常容易被人读懂， 对文件进行分析（parse）也很轻松。","link":"/2019/11/26/redis-learning-1/"},{"title":"redis学习（二）","text":"参见：文章地址 Redis对象类型简介 Redis是一种key/value型数据库，其中，每个key和value都是使用对象表示的。比如，我们执行以下代码： 1redis＞ SET message &quot;hello redis&quot; 其中的key是message，是一个包含了字符串”message”的对象。而value是一个包含了”hello redis”的对象。Redis共有五种对象的类型，分别是： 类型常量 对象的名称 REDIS_STRING 字符串对象 REDIS_LIST 列表对象 REDIS_HASH 哈希对象 REDIS_SET 集合对象 REDIS_ZSET 有序集合对象 Redis中的一个对象的结构体表示如下： 123456789101112131415typedef struct redisObject { // 类型 unsigned type:4; // 编码方式 unsigned encoding: 4; // 引用计数 int refcount; // 指向对象的值 void *ptr; } robj; type表示了该对象的对象类型，即上面五个中的一个。但为了提高存储效率与程序执行效率，每种对象的底层数据结构实现都可能不止一种。encoding就表示了对象底层所使用的编码。 Redis对象底层数据结构 编码常量 编码所对应的底层数据结构 REDIS_ENCODING_INT long 类型的整数 REDIS_ENCODING_EMBSTR embstr 编码的简单动态字符串 REDIS_ENCODING_RAW 简单动态字符串 REDIS_ENCODING_HT 字典 REDIS_ENCODING_LINKEDLIST 双端链表 REDIS_ENCODING_ZIPLIST 压缩列表 REDIS_ENCODING_INTSET 整数集合 REDIS_ENCODING_SKIPLIST 跳跃表和字典 字符串对象 字符串对象的编码可以是int、raw或者embstr如果一个字符串的内容可以转换为long，那么该字符串就会被转换成为long类型，对象的ptr就会指向该long，并且对象类型也用int类型表示。普通的字符串有两种，embstr和raw。embstr应该是Redis 3.0新增的数据结构,在2.8中是没有的。如果字符串对象的长度小于39字节，就用embstr对象。否则用传统的raw对象。 1234567#define REDIS_ENCODING_EMBSTR_SIZE_LIMIT 44 robj *createStringObject(char *ptr, size_t len) { if (len &lt;= REDIS_ENCODING_EMBSTR_SIZE_LIMIT) return createEmbeddedStringObject(ptr,len); else return createRawStringObject(ptr,len); } embstr的好处有如下几点： embstr的创建只需分配一次内存，而raw为两次（一次为sds分配对象，另一次为objet分配对象，embstr省去了第一次）。 相对地，释放内存的次数也由两次变为一次。 embstr的objet和sds放在一起，更好地利用缓存带来的优势。 raw和embstr的区别可以用下面两幅图所示： 列表对象 列表对象的编码可以是ziplist或者linkedlist ziplist是一种压缩链表，它的好处是更能节省内存空间，因为它所存储的内容都是在连续的内存区域当中的。当列表对象元素不大，每个元素也不大的时候，就采用ziplist存储但当数据量过大时就ziplist就不是那么好用了。因为为了保证他存储内容在内存中的连续性，插入的复杂度是O(N)，即每次插入都会重新进行realloc。如下图所示，对象结构中ptr所指向的就是一个ziplist整个ziplist只需要malloc一次，它们在内存中是一块连续的区域。 linkedlist是一种双向链表。它的结构比较简单，节点中存放pre和next两个指针，还有节点相关的信息。当每增加一个node的时候，就需要重新malloc一块内存。 哈希对象 哈希对象的底层实现可以是ziplist或者hashtable。ziplist中的哈希对象是按照key1,value1,key2,value2这样的顺序存放来存储的。当对象数目不多且内容不大时，这种方式效率是很高的。 hashtable的是由dict这个结构来实现的, dict是一个字典，其中的指针dicht ht[2] 指向了两个哈希表 12345678910111213typedef struct dict { dictType *type; void *privdata; dictht ht[2]; long rehashidx; /* rehashing not in progress if rehashidx == -1 */ int iterators; /* number of iterators currently running */ } dict; typedef struct dictht { dictEntry **table; unsigned long size; unsigned long sizemask; unsigned long used; } dictht; dicht[0] 是用于真正存放数据，dicht[1]一般在哈希表元素过多进行rehash的时候用于中转数据。dictht中的table用语真正存放元素了，每个key/value对用一个dictEntry表示，放在dictEntry数组中。 集合对象 集合对象的编码可以是intset或者hashtableintset是一个整数集合，里面存的为某种同一类型的整数，支持如下三种长度的整数： 123#define INTSET_ENC_INT16 (sizeof(int16_t)) #define INTSET_ENC_INT32 (sizeof(int32_t)) #define INTSET_ENC_INT64 (sizeof(int64_t)) intset是一个有序集合，查找元素的复杂度为O(logN)，但插入时不一定为O(logN)，因为有可能涉及到升级操作。比如当集合里全是int16_t型的整数，这时要插入一个int32_t，那么为了维持集合中数据类型的一致，那么所有的数据都会被转换成int32_t类型，涉及到内存的重新分配，这时插入的复杂度就为O(N)了。intset不支持降级操作。 有序集合对象 有序集合的编码可能两种，一种是ziplist，另一种是skiplist与dict的结合。ziplist作为集合和作为哈希对象是一样的，member和score顺序存放。按照score从小到大顺序排列skiplist是一种跳跃表，它实现了有序集合中的快速查找，在大多数情况下它的速度都可以和平衡树差不多。但它的实现比较简单，可以作为平衡树的替代品。它的结构比较特殊。下面分别是跳跃表skiplist和它内部的节点skiplistNode的结构体： 123456789101112131415161718192021222324252627282930/* * 跳跃表 */ typedef struct zskiplist { // 头节点，尾节点 struct zskiplistNode *header, *tail; // 节点数量 unsigned long length; // 目前表内节点的最大层数 int level; } zskiplist; /* ZSETs use a specialized version of Skiplists */ /* * 跳跃表节点 */ typedef struct zskiplistNode { // member 对象 robj *obj; // 分值 double score; // 后退指针 struct zskiplistNode *backward; // 层 struct zskiplistLevel { // 前进指针 struct zskiplistNode *forward; // 这个层跨越的节点数量 unsigned int span; } level[]; } zskiplistNode; head和tail分别指向头节点和尾节点，然后每个skiplistNode里面的结构又是分层的(即level数组)用图表示，大概是下面这个样子： 总结以上简单介绍了Redis的简介，特性以及五种对象类型和五种对象类型的底层实现。事实上，Redis的高效性和灵活性正是得益于同一个对象类型采用不同的底层结构，并且在必要的时候对二者进行转换，还有就是各种底层结构对内存的合理利用。 本文作者：Worktile高级工程师 龚林杰 文章来源：Worktile技术博客","link":"/2019/11/26/redis-learning-2/"}],"tags":[{"name":"LINUX","slug":"LINUX","link":"/tags/LINUX/"},{"name":"I/O","slug":"I-O","link":"/tags/I-O/"},{"name":"linux ","slug":"linux","link":"/tags/linux/"},{"name":"REDIS","slug":"REDIS","link":"/tags/REDIS/"}],"categories":[]}