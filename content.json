{"pages":[],"posts":[{"title":"lru算法","text":"简介​ LRU（Least Recently Used）直译为“最近最少使用”。其实很多老外发明的词直译过来对于我们来说并不是特别好理解，甚至有些词并不在国人的思维模式之内，比如快速排序中的Pivot，模拟信号中的Analog 等等。笔者认为最好的理解方式就是看他诞生的原因，看这个概念的出现如何一步一步演变为现在的样子。为了力求方便理解，下面我们先来看看LRU是什么，主要是为了解决什么问题。 ​ 我们的内存是有限的。所以当缓存数据在内存越来越多，以至于无法存放即将到来的新缓存数据时，就必须扔掉最不常用的缓存数据。所以对于LRU的抽象总结如下： 缓存的容量是有限的 当缓存容量不足以存放需要缓存的新数据时，必须丢掉最不常用的缓存数据 实现LRU​ 1.用一个数组来存储数据，给每一个数据项标记一个访问时间戳，每次插入新数据项的时候，先把数组中存在的数据项的时间戳更新。当数组空间已满时，将时间戳最小的数据项淘汰。 ​ 2.利用一个链表来实现，每次新插入数据的时候将新数据插到链表的头部；每次缓存命中（即数据被访问），则将数据移到链表头部；那么当链表满的时候，就将链表尾部的数据丢弃。 ​ 3.利用链表和hashmap。当需要插入新的数据项的时候，如果新数据项在链表中存在（一般称为命中），则把该节点移到链表头部，如果不存在，则新建一个节点，放到链表头部，若缓存满了，则把链表最后一个节点删除即可。在访问数据的时候，如果数据项在链表中存在，则把该节点移到链表头部，否则返回-1。这样一来在链表尾部的节点就是最近最久未访问的数据项。 比较 ​ 对于第一种方法，需要不停地维护数据项的访问时间戳，另外，在插入数据、删除数据以及访问数据时，时间复杂度都是O(n)。对于第二种方法，链表在定位数据的时候时间复杂度为O(n)。所以在一般使用第三种方式来是实现LRU算法。 1234567891011121314151617181920212223public class LruLinkedHashMap&lt;K, V&gt; extends LinkedHashMap&lt;K, V&gt; { private Integer cacheSize; public LruLinkedHashMap(int initialCapacity) { // 由于LinkedHashMap是为自动扩容的，当table数组中元素大于Capacity * loadFactor的时候，就会自动进行两倍扩容。但是为了使缓存大小固定，就需要在初始化的时候传入容量大小和负载因子。为了使得到达设置缓存大小不会进行自动扩容，需要将初始化的大小进行计算再传入 int capacity = (int)Math.ceil(initialCapacity / 0.75f) + 1; /* * 第三个参数设置为true，代表linkedlist按访问顺序排序，可作为LRU缓存 * 第三个参数设置为false，代表按插入顺序排序，可作为FIFO缓存 */ super(capacity, 0.75f, true); cacheSize = initialCapacity; } @Override protected boolean removeEldestEntry(Map.Entry&lt;K, V&gt; eldest) { //当返回true的时候，就会remove其中最久的元素 return size() &gt; cacheSize; }} 参见：LRU","link":"/2019/11/28/algorithm-lru/"},{"title":"dubbo学习","text":"#学习资料 ​ 学习的最好资料来源是官方文档和源码 ​ 这里官方已经很全面了，包括了SPI，服务的引入导出，路由，集群，均衡策略，服务调用过程都做了详细的源码分析。 详细参见：官方Dubbo 服务调用过程 #MOCK测试平台思路： ​ 参考dubbo的mock方式，实际项目中测试需要一些数据及结果流程比较长而且复杂，可以抽象一种类似的MOCK方式来简化此过程，参见基于 Dubbo 分布式服务框架的一种 MOCK 方式 使用mockito框架mock掉整个RedisTemplate的示例 回声测试 回声测试用于检测服务是否可用，回声测试按照正常请求流程执行，能够测试整个调用是否畅通，可用于监控。 所有服务自动实现EchoService接口，只需要将任意服务引用强制转换为EchoService，即可使用。 Dubbo中的回声测试是如何实现的？为什么能将任意的服务引用都强制转为EchoService？ 流程： java中关于强制转换的一个限制：必须有继承关系，就是说两个类之间要能够进行类型转换，必须有继承关系才可以。 可是很明显，我们写的Dubbo服务接口是与EchoService接口没有任何集成关系的，这是如何实现的呢？ 服务创建动态代理的时候，是在传入的接口中人为的增加了“EchoService.class”接口 EchoService接口中的方法是怎么实现的呢? 因为Dubbo提供了很多Filter，针对这个EchoService提供了一个EchoFilter实现 12EchoService echoService = (EchoService) demoService;System.out.println(echoService.$echo(\"hello\")); 隐式参数&amp;上下文dubbo一些你不一定知道但是很好用的功能","link":"/2019/12/05/dubbo-pre/"},{"title":"epoll理论解读","text":"I/O的操作 首先我们来定义流的概念，一个流可以是文件，socket，pipe等等可以进行I/O操作的内核对象。 不管是文件，还是套接字，还是管道，我们都可以把他们看作流。 之后我们来讨论I/O的操作，通过read，我们可以从流中读入数据；通过write，我们可以往流写入数据。现在假定一个情形，我们需要从流中读数据，但是流中还没有数据，（典型的例子为，客户端要从socket读如数据，但是服务器还没有把数据传回来），这时候该怎么办？ 阻塞非阻塞阻塞I/O模式阻塞I/O模式下，一个线程只能处理一个流的I/O事件。如果想要同时处理多个流，要么多进程(fork)，要么多线程(pthread_create)，很不幸这两种方法效率都不高。 非阻塞忙轮询的I/O 于是再来考虑非阻塞忙轮询的I/O方式，我们发现我们可以同时处理多个流了（把一个流从阻塞模式切换到非阻塞模式再此不予讨论）： while true { for i in stream[]; { if i has data read until unavailable } } 我们只要不停的把所有流从头到尾问一遍，又从头开始。这样就可以处理多个流了，但这样的做法显然不好，因为如果所有的流都没有数据，那么只会白白浪费CPU。这里要补充一点，阻塞模式下，内核对于I/O事件的处理是阻塞或者唤醒，而非阻塞模式下则把I/O事件交给其他对象（后文介绍的select以及epoll）处理甚至直接忽略。 select 为了避免CPU空转，可以引进了一个代理（一开始有一位叫做select的代理，后来又有一位叫做poll的代理，不过两者的本质是一样的）。这个代理比较厉害，可以同时观察许多流的I/O事件，在空闲的时候，会把当前线程阻塞掉，当有一个或多个流有I/O事件时，就从阻塞态中醒来，于是我们的程序就会轮询一遍所有的流（于是我们可以把“忙”字去掉了）。代码长这样: while true { select(streams[]) for i in streams[] { if i has data read until unavailable } } 于是，如果没有I/O事件产生，我们的程序就会阻塞在select处。但是依然有个问题，我们从select那里仅仅知道了，有I/O事件发生了，但却并不知道是那几个流（可能有一个，多个，甚至全部），我们只能无差别轮询所有流，找出能读出数据，或者写入数据的流，对他们进行操作。 但是使用select，我们有O(n)的无差别轮询复杂度，同时处理的流越多，没一次无差别轮询时间就越长。再次 说了这么多，终于能好好解释epoll了 epoll epoll可以理解为event poll，不同于忙轮询和无差别轮询，epoll之会把哪个流发生了怎样的I/O事件通知我们。此时我们对这些流的操作都是有意义的。（复杂度降低到了O(1)） 在讨论epoll的实现细节之前，先把epoll的相关操作列出： epoll_create 创建一个epoll对象，一般epollfd = epoll_create() epoll_ctl （epoll_add/epoll_del的合体），往epoll对象中增加/删除某一个流的某一个事件 比如 epoll_ctl(epollfd, EPOLL_CTL_ADD, socket, EPOLLIN);//注册缓冲区非空事件，即有数据流入 epoll_ctl(epollfd, EPOLL_CTL_DEL, socket, EPOLLOUT);//注册缓冲区非满事件，即流可以被写入 epoll_wait(epollfd,…)等待直到注册的事件发生 （注：当对一个非阻塞流的读写发生缓冲区满或缓冲区空，write/read会返回-1，并设置errno=EAGAIN。而epoll只关心缓冲区非满和缓冲区非空事件）。 一个epoll模式的代码大概的样子是： while true { active_stream[] = epoll_wait(epollfd) for i in active_stream[] { read or write till } } 参照： 通俗解读：https://blog.csdn.net/u011671986/article/details/79449853 详细解读：https://bbs.gameres.com/thread_842984_1_1.html","link":"/2019/11/25/epoll/"},{"title":"Hello World","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new \"My New Post\" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","link":"/2019/11/14/hello-world/"},{"title":"http1.x、http 2和https","text":"一、HTTP/1.xHttp1.x 缺陷：线程阻塞，在同一时间，同一域名的请求有一定数量限制，超过限制数目的请求会被阻塞 http1.0 缺陷：浏览器与服务器只保持短暂的连接，浏览器的每次请求都需要与服务器建立一个TCP连接（TCP连接的新建成本很高，因为需要客户端和服务器三次握手），服务器完成请求处理后立即断开TCP连接，服务器不跟踪每个客户也不记录过去的请求； 解决方案： 添加头信息——非标准的Connection字段Connection: keep-alive http1.1： 改进点： 持久连接 引入了持久连接，即TCP连接默认不关闭，可以被多个请求复用，不用声明Connection: keep-alive(对于同一个域名，大多数浏览器允许同时建立6个持久连接) 管道机制 即在同一个TCP连接里面，客户端可以同时发送多个请求。 分块传输编码 即服务端没产生一块数据，就发送一块，采用”流模式”而取代”缓存模式”。 新增请求方式 PUT:请求服务器存储一个资源; DELETE：请求服务器删除标识的资源； OPTIONS：请求查询服务器的性能，或者查询与资源相关的选项和需求； TRACE：请求服务器回送收到的请求信息，主要用于测试或诊断； CONNECT：保留将来使用 缺点： 虽然允许复用TCP连接，但是同一个TCP连接里面，所有的数据通信是按次序进行的。服务器只有处理完一个请求，才会接着处理下一个请求。如果前面的处理特别慢，后面就会有许多请求排队等着。这将导致“队头堵塞” 避免方式：一是减少请求数，二是同时多开持久连接 二、HTTP/2.0 特点： 采用二进制格式而非文本格式； 完全多路复用，而非有序并阻塞的、只需一个连接即可实现并行； 使用报头压缩，降低开销 服务器推送 1. 二进制协议 HTTP/1.1 版的头信息肯定是文本（ASCII编码），数据体可以是文本，也可以是二进制。HTTP/2 则是一个彻底的二进制协议，头信息和数据体都是二进制，并且统称为”帧”：头信息帧和数据帧。 二进制协议解析起来更高效、“线上”更紧凑，更重要的是错误更少。 2. 完全多路复用 HTTP/2 复用TCP连接，在一个连接里，客户端和浏览器都可以同时发送多个请求或回应，而且不用按照顺序一一对应，这样就避免了”队头堵塞”。 3. 报头压缩 HTTP 协议是没有状态，导致每次请求都必须附上所有信息。所以，请求的很多头字段都是重复的，比如Cookie，一样的内容每次请求都必须附带，这会浪费很多带宽，也影响速度。 对于相同的头部，不必再通过请求发送，只需发送一次； HTTP/2 对这一点做了优化，引入了头信息压缩机制； 一方面，头信息使用gzip或compress压缩后再发送； 另一方面，客户端和服务器同时维护一张头信息表，所有字段都会存入这个表，产生一个索引号，之后就不发送同样字段了，只需发送索引号。 4. 服务器推送 HTTP/2 允许服务器未经请求，主动向客户端发送资源； 通过推送那些服务器任务客户端将会需要的内容到客户端的缓存中，避免往返的延迟 三、HTTPS HTTP协议通常承载于TCP协议之上，在HTTP和TCP之间添加一个安全协议层（SSL或TSL），这个时候，就成了我们常说的HTTPS. 1、HTTPS主要作用12- （1）对数据进行加密，并建立一个信息安全通道，来保证传输过程中的数据安全;- （2）对网站服务器进行真实身份认证。 2、HTTPS和HTTP的区别12345- 1、HTTPS是加密传输协议，HTTP是名文传输协议;- 2、HTTPS需要用到SSL证书，而HTTP不用;- 3、HTTPS比HTTP更加安全，对搜索引擎更友好，利于SEO,- 4、HTTPS标准端口443，HTTP标准端口80;- 5、HTTPS基于传输层，HTTP基于应用层; 3、HTTPS和HTTP的工作过程区别 HTTP 包含动作： 浏览器打开一个 TCP 连接 浏览器发送 HTTP 请求到服务器端 服务器发送 HTTP 回应信息到浏览器 TCP 连接关闭 SSL 包含动作： 验证服务器端 客户端和服务器端选择加密算法和密码，确保双方都支持 验证客户端(可选) 使用公钥加密技术来生成共享加密数据 创建一个加密的 SSL 连接 基于该 SSL 连接传递 HTTP 请求 4、HTTPS加密方式 对称加密：加密和解密都是使用的同一个密钥； 非对称加密： 加密使用的密钥和解密使用的密钥是不相同的，分别称为：公钥、私钥； 公钥和算法都是公开的，私钥是保密的。 非对称加密过程： 服务端生成配对的公钥和私钥 私钥保存在服务端，公钥发送给客户端 客户端使用公钥加密明文传输给服务端 服务端使用私钥解密密文得到明文 数字签名：签名就是在信息的后面再加上一段内容，可以证明信息没有被修改过。 引用：深入理解http1.x、http 2和https HTTP/2详解 HTTP与HTTPS的区别","link":"/2019/12/13/http-pre/"},{"title":"I/O模型(同步，异步，阻塞，非阻塞)","text":"思考：​ 同步（synchronous） IO和异步（asynchronous） IO，阻塞（blocking） IO和非阻塞（non-blocking）IO分别是什么，到底有什么区别？ ​ 用户进程，系统进程注意区分 IO发生时涉及的对象和步骤​ 对于一个network IO (这里我们以read举例)，它会涉及到两个系统对象，一个是调用这个IO的process (or thread)，另一个就是系统内核(kernel)。当一个read操作发生时，它会经历两个阶段： 等待数据准备 (Waiting for the data to be ready) 将数据从内核拷贝到进程中 (Copying the data from the kernel to the proces) 记住这两点很重要，因为这些IO Model的区别就是在两个阶段上各有不同的情况。 Stevens在文章中一共比较了五种IO Model blocking IO(阻塞) nonblocking IO(非阻塞) IO multiplexing（多路复用） signal driven IO（信号驱动） asynchronous IO（异步） blocking IO ​ 当用户进程调用了recvfrom这个系统调用，kernel就开始了IO的第一个阶段：准备数据。对于network io来说，很多时候数据在一开始还没有到达（比如，还没有收到一个完整的UDP包），这个时候kernel就要等待足够的数据到来。而在用户进程这边，整个进程会被阻塞。当kernel一直等到数据准备好了，它就会将数据从kernel中拷贝到用户内存，然后kernel返回结果，用户进程才解除block的状态，重新运行起来。所以，blocking IO的特点就是在IO执行的两个阶段都被block了。 non-blocking IO ​ 当用户进程发出read操作时，如果kernel中的数据还没有准备好，那么它并不会block用户进程，而是立刻返回一个error。从用户进程角度讲 ，它发起一个read操作后，并不需要等待，而是马上就得到了一个结果。用户进程判断结果是一个error时，它就知道数据还没有准备好，于是它可以再次发送read操作。一旦kernel中的数据准备好了，并且又再次收到了用户进程的system call，那么它马上就将数据拷贝到了用户内存，然后返回。所以，用户进程其实是需要不断的主动询问kernel数据好了没有。 IO multiplexing​ IO multiplexing这个词可能有点陌生，但是如果我说select，epoll，大概就都能明白了。有些地方也称这种IO方式为event driven IO。我们都知道，select/epoll的好处就在于单个process就可以同时处理多个网络连接的IO。它的基本原理就是select/epoll这个function会不断的轮询所负责的所有socket，当某个socket有数据到达了，就通知用户进程。它的流程如图： ​ 当用户进程调用了select，那么整个进程会被block，而同时，kernel会“监视”所有select负责的socket，当任何一个socket中的数据准备好了，select就会返回。这个时候用户进程再调用read操作，将数据从kernel拷贝到用户进程。 这个图和阻塞IO的图其实并没有太大的不同，事实上，还更差一些。因为这里需要使用两个system call (select 和 recvfrom)，而blocking IO只调用了一个system call (recvfrom)。但是，用select的优势在于它可以同时处理多个connection。（所以，如果处理的连接数不是很高的话，使用select/epoll的web server不一定比使用multi-threading + blocking IO的web server性能更好，可能延迟还更大。select/epoll的优势并不是对于单个连接能处理得更快，而是在于能处理更多的连接。）​ 在IO multiplexing Model中，实际中，对于每一个socket，一般都设置成为non-blocking，但是，如上图所示，整个用户的进程其实是一直被block的。只不过进程是被select这个函数block，而不是被socket IO给block。​ signal driven IO Asynchronous I/O​ 这类函数的工作机制是告知内核启动某个操作，并让内核在整个操作（包括将数据从内核拷贝到用户空间）完成后通知我们。 ​ 用户进程发起read操作之后，立刻就可以开始去做其它的事。而另一方面，从kernel的角度，当它受到一个asynchronous read之后，首先它会立刻返回，所以不会对用户进程产生任何block。然后，kernel会等待数据准备完成，然后将数据拷贝到用户内存，当这一切都完成之后，kernel会给用户进程发送一个signal，告诉它read操作完成了。 QAblocking和non-blocking的区别​ 调用blocking IO会一直block住对应的进程直到操作完成，而non-blocking IO在kernel还准备数据的情况下会立刻返回。 synchronous IO和asynchronous IO的区别​ Stevens给出的定义（其实是POSIX的定义）是这样子的：​ A synchronous I/O operation causes the requesting process to be blocked until that I/O operation completes;​ An asynchronous I/O operation does not cause the requesting process to be blocked; ​ 两者的区别就在于synchronous IO做”IO operation”的时候会将process阻塞。按照这个定义，之前所述的blocking IO，non-blocking IO，IO multiplexing都属于synchronous IO。 ​ 定义中所指的”IO operation”是指真实的IO操作，就是例子中的recvfrom这个system call。 non-blocking IO和asynchronous IO的区别​ 区别在于非阻塞在第一个阶段check第二阶段block，异步全程交给kenel处理 参照https://blog.csdn.net/historyasamirror/article/details/5778378 Richard Stevens的“UNIX® Network Programming Volume 1, Third Edition: The Sockets Networking ”，6.2节“I/O Models ”","link":"/2019/11/25/io-learning/"},{"title":"jvm","text":"PermGen space和heap space区别12PermGen space说明方法区OOMheap space 堆中OOM jdk8真正开始废弃永久代，而使用元空间(Metaspace)","link":"/2019/12/13/jvm-pre/"},{"title":"linux内存swap","text":"什么是linux的内存机制​ 我们知道，直接从物理内存读写数据要比从硬盘读写数据要快的多，因此，我们希望所有数据的读取和写入都在内存完成，而内存是有限的，这样就引出了物理内存与虚拟内存的概念。 ​ 物理内存就是系统硬件提供的内存大小，是真正的内存，相对于物理内存，在linux下还有一个虚拟内存的概念，虚拟内存就是为了满足物理内存的不足而提出的策略，它是利用磁盘空间虚拟出的一块逻辑内存，用作虚拟内存的磁盘空间被称为交换空间（Swap Space）。 ​ 作为物理内存的扩展，linux会在物理内存不足时，使用交换分区的虚拟内存，更详细的说，就是内核会将暂时不用的内存块信息写到交换空间，这样以来，物理内存得到了释放，这块内存就可以用于其它目的，当需要用到原始的内容时，这些信息会被重新从交换空间读入物理内存。 ​ Linux的内存管理采取的是分页存取机制，为了保证物理内存能得到充分的利用，内核会在适当的时候将物理内存中不经常使用的数据块自动交换到虚拟内存中，而将经常使用的信息保留到物理内存。 ​ 要深入了解linux内存运行机制，需要知道下面提到的几个方面： Linux系统会不时的进行页面交换操作，以保持尽可能多的空闲物理内存，即使并没有什么事情需要内存，Linux也会交换出暂时不用的内存页面。这可以避免等待交换所需的时间。 Linux 进行页面交换是有条件的，不是所有页面在不用时都交换到虚拟内存，linux内核根据”最近最经常使用“算法，仅仅将一些不经常使用的页面文件交换到虚拟 内存，有时我们会看到这么一个现象：linux物理内存还有很多，但是交换空间也使用了很多。其实，这并不奇怪，例如，一个占用很大内存的进程运行时，需 要耗费很多内存资源，此时就会有一些不常用页面文件被交换到虚拟内存中，但后来这个占用很多内存资源的进程结束并释放了很多内存时，刚才被交换出去的页面 文件并不会自动的交换进物理内存，除非有这个必要，那么此刻系统物理内存就会空闲很多，同时交换空间也在被使用，就出现了刚才所说的现象了。关于这点，不 用担心什么，只要知道是怎么一回事就可以了。 交换空间的页面在使用时会首先被交换到物理内存，如果此时没有足够的物理内存来容纳这些页 面，它们又会被马上交换出去，如此以来，虚拟内存中可能没有足够空间来存储这些交换页面，最终会导致linux出现假死机、服务异常等问题，linux虽 然可以在一段时间内自行恢复，但是恢复后的系统已经基本不可用了。 因此，合理规划和设计Linux内存的使用，是非常重要的. ​ 在Linux 操作系统中，当应用程序需要读取文件中的数据时，操作系统先分配一些内存，将数据从磁盘读入到这些内存中，然后再将数据分发给应用程序；当需要往文件中写 数据时，操作系统先分配内存接收用户数据，然后再将数据从内存写到磁盘上。然而，如果有大量数据需要从磁盘读取到内存或者由内存写入磁盘时，系统的读写性 能就变得非常低下，因为无论是从磁盘读数据，还是写数据到磁盘，都是一个很消耗时间和资源的过程，在这种情况下，Linux引入了buffers和 cached机制。 ​ buffers与cached都是内存操作，用来保存系统曾经打开过的文件以及文件属性信息，这样当操作系统需要读取某些文件时，会首先在buffers 与cached内存区查找，如果找到，直接读出传送给应用程序，如果没有找到需要数据，才从磁盘读取，这就是操作系统的缓存机制，通过缓存，大大提高了操 作系统的性能。但buffers与cached缓冲的内容却是不同的。 ​ buffers是用来缓冲块设备做的，它只记录文件系统的元数据（metadata）以及 tracking in-flight pages，而cached是用来给文件做缓冲。更通俗一点说：buffers主要用来存放目录里面有什么内容，文件的属性以及权限等等。 创建SWAP内存1234567891011创建2G的空间dd if=/dev/zero of=/root/swapfile1 bs=1M count=2048创建swap分区mkswap /root/swapfile1开启虚拟内存chmod 0600 /root/swapfile1swapon /root/swapfile1设定虚拟内存开机自动挂载echo &quot;/root/swapfile1 swap swapdefaults 0 0&quot; &gt;&gt; /etc/fstab查看虚拟内存信息free -m或者swapon -s以及ll -h 和df -h 取消SWAP内存123456取消 SWAP文件swapoff /root/swapfile1取消开机启动加载sed -i &quot;/swapfile1/d&quot; /etc/fstab删除 SWAP文件rm -rf /root/swapfile1","link":"/2019/11/14/linux%E5%86%85%E5%AD%98swap/"},{"title":"MQ学习（一）","text":"MQ的作用​ 消息队列中间件主要解决应用解耦，异步消息，流量削锋等问题 MQ带来的新问题​ 一般而言，引入的外部依赖越多，系统越脆弱。需要考虑消息的重复消费、消息丢失、保证消费顺序、数据一致性问题等 幂等及去重​ 幂等性：就是用户对于同一操作发起的一次请求或者多次请求的结果是一致的 ​ 去重策略：保证每条消息都有唯一编号(比如唯一流水号) ​ 方法1: 建立一个消息表，拿到这个消息做数据库的insert操作。给这个消息做一个唯一主键（primary key）或者唯一约束(uniq key)，那么就算出现重复消费的情况，就会导致主键冲突，那么就不再处理这条消息。 参见","link":"/2019/12/02/mq-pre/"},{"title":"mysql索引","text":"聚簇索引与非聚簇索引定义​ 聚簇索引是对磁盘上实际数据重新组织以按指定的一个或多个列的值排序的算法。特点是存储数据的顺序和索引顺序一致。​ 一般情况下主键会默认创建聚簇索引，且一张表只允许存在一个聚簇索引。 ​ 在《数据库原理》一书中是这么解释聚簇索引和非聚簇索引的区别的：​ 聚簇索引的叶子节点就是数据节点，而非聚簇索引的叶子节点仍然是索引节点，只不过有指向对应数据块的指针。 综上，可以得出聚簇索引和非聚簇索引概念： 聚簇索引：即存储索引值，又存储行数据，数据文件和索引文件是同一个文件 非聚簇索引：索引文件和数据文件是独立分开的 ​ 那么如果数据表中没有主键呢？MySQL的解决办法是隐式地将一个唯一的非空的列定义为聚簇。那如果这也没有呢？MySQL就自己创建一个聚簇索引。 ​ 在Innodb中，二级索引除了存储本身的列值外，其叶子节点存储的不是‘行指针’，而是主键值，为什么是这样呢？原来这种方式在表结构发生变化的时候会有很大的优势。如果二级索引的存储顺序是以列值为基础的，那么在发生数据行的移动或者增加删除时候，必定会引起索引结构的巨大变化。 MyISAM与InnoDB​ mysql存储引擎MyISAM与InnoDB的底层数据结构的区别主要有，在磁盘上存储的文件以及存储索引以及组织存储索引的方式不同； MyISAM索引文件和数据文件是分离的(非聚集)，索引的叶节点存放的是对应索引在文件系统中的数据地址编码 innodb中，数据文件和索引文件是同一个文件，是聚簇索引。（注意区别普通索引） （1）InnoDB的主键采用聚簇索引存储，使用的是B+Tree作为索引结构，但是叶子节点存储的是索引值和数据本身（注意和MyISAM的不同）。（2）InnoDB的二级索引不使用聚蔟索引，叶子节点存储的是KEY字段加主键值。因此，通过二级索引查询首先查到是主键值，然后InnoDB再根据查到的主键值通过主键索引找到相应的数据块。（3）MyISAM的主键索引和二级索引叶子节点存放的都是列值与行号的组合，叶子节点中保存的是数据的物理地址（4）MyISAM引擎使用B+Tree作为索引结构，叶节点的data域存放的是数据记录的地址（5）为什么用B+Tree 不是BTree： B-Tree：如果一次检索需要访问4个节点，数据库系统设计者利用磁盘预读原理，把节点的大小设计为一个页，那读取一个节点只需要一次I/O操作，完成这次检索操作，最多需要3次I/O(根节点常驻内存)。数据记录越小，每个节点存放的数据就越多，树的高度也就越小，I/O操作就少了，检索效率也就上去了。 B+Tree：非叶子节点只存key，大大滴减少了非叶子节点的大小，那么每个节点就可以存放更多的记录，树更矮了，I/O操作更少了。所以B+Tree拥有更好的性能。 ​ 由于节子节点(数据页)只能按照一颗B+树排序，故一张表只能有一个聚簇索引。辅助索引的存在不影响聚簇索引中数据的组织，所以一张表可以有多个辅助索引 参照：mysql InnoDB index 主键采用聚簇索引，二级索引不采用聚簇索引","link":"/2019/12/13/mysql-index/"},{"title":"reactor和preactor模型","text":"Reactor模型Reactor的核心思想： 将关注的I/O事件注册到多路复用器上，一旦有I/O事件触发，将事件分发到事件处理器中，执行就绪I/O事件对应的处理函数中。模型中有三个重要的组件： 多路复用器：由操作系统提供接口，Linux提供的I/O复用接口有select、poll、epoll； 事件分离器：将多路复用器返回的就绪事件分发到事件处理器中； 事件处理器：处理就绪事件处理函数。 Handle：标示文件描述符； Event Demultiplexer：执行多路事件分解操作，对操作系统内核实现I/O复用接口的封装；用于阻塞等待发生在句柄集合上的一个或多个事件（如select/poll/epoll）； Event Handler：事件处理接口； Event Handler A(B)：实现应用程序所提供的特定事件处理逻辑； Reactor：反应器，定义一个接口，实现以下功能： a)供应用程序注册和删除关注的事件句柄； b)运行事件处理循环； c)等待的就绪事件触发，分发事件到之前注册的回调函数上处理. 经典Reactor模式 在经典Reactor模式中，包含以下角色： Reactor ：将I/O事件发派给对应的Handler Acceptor ：处理客户端连接请求 Handlers ：执行非阻塞读/写 多工作线程Reactor模式 多Reactor的Reactor模式 Proactor模型​ 与Reactor不同的是，Proactor使用异步I/O系统接口将I/O操作托管给操作系统，Proactor模型中分发处理异步I/O完成事件，并调用相应的事件处理接口来处理业务逻辑。 Proactor类结构中包含有如下角色： Handle：用来标识socket连接或是打开文件； Async Operation Processor：异步操作处理器；负责执行异步操作，一般由操作系统内核实现； Async Operation：异步操作； Completion Event Queue：完成事件队列；异步操作完成的结果放到队列中等待后续使用； Proactor：主动器；为应用程序进程提供事件循环；从完成事件队列中取出异步操作的结果，分发调用相应的后续处理逻辑； Completion Handler：完成事件接口；一般是由回调函数组成的接口； Completion Handler A(B)：完成事件处理逻辑；实现接口定义特定的应用处理逻辑。 支持情况​ windows对异步I/O提供了非常好的支持，常用Proactor的模型实现服务器；而Linux对异步I/O操作(aio接口)的支持并不是特别理想，而且不能直接处理accept，因此Linux平台上还是以Reactor模型为主。 ​ 目前实现了纯异步操作的操作系统少，实现优秀的如windows IOCP，但由于其windows系统用于服务器的局限性，目前应用范围较小；而Unix/Linux系统对纯异步的支持有限，应用事件驱动的主流还是通过select/epoll来实现； java提供Asynchronous I/O相关接口以支持异步I/O，AIO有两种api进行操作： Future 方式 即提交一个 I/O 操作请求，返回一个 Future。然后您可以对 Future 进行检查，确定它是否完成，或者阻塞 IO 操作直到操作正常完成或者超时异常。 Callback 方式 即提交一个 I/O 操作请求，并且指定一个 CompletionHandler。当异步 I/O 操作完成时，便发送一个通知，此时这个 CompletionHandler 对象的 completed 或者 failed 方法将会被调用。 参照： https://www.jianshu.com/p/b4de9b85c79d","link":"/2019/11/25/reactor/"},{"title":"redis学习（一）","text":"简介REmote DIctionary Server(Redis) 是一个由SalvatoreSanfilippo写的key-value存储系统。 Redis是一个开源的使用ANSI C语言编写、遵守BSD协议、支持网络、可基于内存亦可持久化的日志型、Key-Value数据库，并提供多种语言的API。 它通常被称为数据结构服务器，因为值（value）可以是字符串(String), 哈希(Map), 列表(list), 集合(sets) 和有序集合(sorted sets)等类型。 Redis 与其他 key - value 缓存产品有以下三个特点： Redis支持数据的持久化，可以将内存中的数据保持在磁盘中，重启的时候可以再次加载进行使用。 Redis不仅仅支持简单的key-value类型的数据，同时还提供list，set，zset，hash等数据结构的存储。 Redis支持数据的备份，即master-slave模式的数据备份。 redis常用数据类型 String Hash List Set Sorted set redis其他数据类型​ Bitmap:位图是支持按 bit 位来存储信息，可以用来实现 布隆过滤器（BloomFilter）； ​ HyperLogLog:供不精确的去重计数功能，比较适合用来做大规模数据的去重统计，例如统计 UV； ​ Geospatial:可以用来保存地理位置，并作位置距离计算或者根据半径计算位置等。 ​ … ​ Pipeline：执行批量指令，一次性返回全部结果，可以减少频繁的请求应答。 ​ Lua：脚本，可以执行一系列的功能。利用他的原子性。 ​ 事物：Redis 提供的不是严格的事务，只保证串行执行命令，并且能保证全部执行，但是执行命令失败时并不会回滚，而是会继续执行下去。 redis常用命令 Key（键） String Hash List Set Sorted set pub/sub（发布／订阅） Transactions（事物） Script（脚本） Conection（链接） Server（服务器） 后面五个不常用，具体命令操作参见地址： 官方 翻译 redis持久化（RDB／AOF） RDB 持久化可以在指定的时间间隔内生成数据集的时间点快照（point-in-time snapshot）。 AOF 持久化记录服务器执行的所有写操作命令，并在服务器启动时，通过重新执行这些命令来还原数据集。 AOF 文件中的命令全部以 Redis 协议的格式来保存，新命令会被追加到文件的末尾。 Redis 还可以在后台对 AOF 文件进行重写（rewrite），使得 AOF 文件的体积不会超出保存数据集状态所需的实际大小。 Redis 还可以同时使用 AOF 持久化和 RDB 持久化。 在这种情况下， 当 Redis 重启时， 它会优先使用 AOF 文件来还原数据集， 因为 AOF 文件保存的数据集通常比 RDB 文件所保存的数据集更完整。 你甚至可以关闭持久化功能，让数据只在服务器运行时存在。 缺点： RDB： 1.设置不同的保存点（save point）来控制保存 RDB 文件的频率，一旦发生故障可能会丢失数据。 2.每次保存 RDB 的时候，Redis 都要 fork() 出一个子进程，并由子进程来进行实际的持久化工作。 在数据集比较庞大时， fork() 可能会非常耗时，造成服务器在某某毫秒内停止处理客户端； AOF： 1.相同的数据集来说，AOF 文件的体积通常要大于 RDB 文件的体积。 2…. 优点： RDB： 1.保存了 Redis 在某个时间点上的数据集。 这种文件非常适合用于进行备份 2.速度快，无论保存还是恢复 AOF： 1.非常耐久（much more durable） 2.AOF 文件是一个只进行追加操作的日志文件（append only log）， 因此对 AOF 文件的写入不需要进行 seek 3.在 AOF 文件体积变得过大时，自动地在后台对 AOF 进行重写： 重写后的新 AOF 文件包含了恢复当前数据集所需的最小命令集合。 4.AOF 文件有序地保存了对数据库执行的所有写入操作， 这些写入操作以 Redis 协议的格式保存， 因此 AOF 文件的内容非常容易被人读懂， 对文件进行分析（parse）也很轻松。 setex和setnx命令区别 123456789SETEX key seconds value将值 value 关联到 key ，并将 key 的生存时间设为 seconds (以秒为单位)。如果 key 已经存在， SETEX 命令将覆写旧值。 这个命令类似于以下两个命令： SET key value EXPIRE key seconds # 设置生存时间不同之处是， SETEX 是一个原子性(atomic)操作，关联值和设置生存时间两个动作会在同一时间内完成，该命令在 Redis 用作缓存时，非常实用。 1234SETNX key value将 key 的值设为 value ，当且仅当 key 不存在。若给定的 key 已经存在，则 SETNX 不做任何动作。SETNX 是『SET if Not eXists』(如果不存在，则 SET)的简写。 Redis 事物redis 数据库一致性数据淘汰策略redis 提供 6种数据淘汰策略： volatile-lru：从已设置过期时间的数据集（server.db[i].expires）中挑选最近最少使用的数据淘汰 volatile-ttl：从已设置过期时间的数据集（server.db[i].expires）中挑选将要过期的数据淘汰 volatile-random：从已设置过期时间的数据集（server.db[i].expires）中任意选择数据淘汰 allkeys-lru：当内存不足以容纳新写入数据时，在键空间中，移除最近最少使用的key（这个是最常用的）. allkeys-random：从数据集（server.db[i].dict）中任意选择数据淘汰 no-eviction：禁止驱逐数据，也就是说当内存不足以容纳新写入数据时，新写入操作会报错。 TTL设置过期时间，Redis如何对这批key进行删除？ ​ 定期删除+惰性删除 ​ 定期删除，指的是redis默认是每隔100ms就随机抽取一些设置了过期时间的key，随机抽取一些key来检查和删除的。（全部检查，那redis基本上就死了，cpu负载会很高的，消耗在你的检查过期key上了。） ​ 问题是，定期删除可能会导致很多过期key到了时间并没有被删除掉，那咋整呢？所以就是惰性删除了。这就是说，在你获取某个key的时候，redis会检查一下 ，这个key如果设置了过期时间那么是否过期了？如果过期了此时就会删除，不会给你返回任何东西。","link":"/2019/11/26/redis-learning-1/"},{"title":"redis学习（三）","text":"缓存的击穿 穿透 和 雪崩缓存雪崩​ 缓存雪崩是指在我们设置缓存时采用了相同的过期时间，导致缓存在某一时刻同时失效，请求全部转发到，瞬时压力过重雪崩。或在大部分数据都没缓存的时候被一次性同时访问。 解决方案： 缓存失效时的雪崩效应对底层系统的冲击非常可怕。我们可以用以下方式来避免： 1.数据预热： 可以通过缓存reload机制，预先去更新缓存，再即将发生大并发访问前手动触发加载缓存不同的key，设置不同的过期时间，让缓存失效的时间点尽量均匀 2.做二级缓存，或者双缓存策略： A1为原始缓存，A2为拷贝缓存，A1失效时，可以访问A2，A1缓存失效时间设置为短期，A2设置为长期。 3.缓存永远不过期： 这里的“永远不过期”包含两层意思： 1)从缓存上看，确实没有设置过期时间，这就保证了，不会出现热点key过期问题，也就是“物理”不过期。 2)从功能上看，如果不过期，那不就成静态的了吗？所以我们把过期时间存在key对应的里，如果发现要过期了，通过一个后台的异步线程进行缓存的构建，也就是“逻辑”过期. ​ 4.用主从模式和集群模式来尽量保证缓存服务的高可用。 缓存击穿​ 对于一些设置了过期时间的key，如果这些key可能会在某些时间点被超高并发地访问，是一种非常“热点”的数据，这个时候，需要考虑一个问题：缓存被“击穿”的问题。 ​ 这个和缓存雪崩的区别在于这里针对某一key缓存，前者则是很多key。缓存在某个时间点过期的时候，恰好在这个时间点对这个Key有大量的并发请求过来，这些请求发现缓存过期一般都会从后端DB加载数据并回设到缓存，这个时候大并发的请求可能会瞬间把后端DB压垮。 解决方案： 1.使用互斥锁(mutex key) 业界比较常用的做法，是使用mutex。简单地来说，就是在缓存失效的时候（判断拿出来的值为空），不是立即去load db，而是先使用缓存工具的某些带成功操作返回值的操作（比如mutex key，当操作返回成功时，再进行Redis的SETNX或者Memcache的ADD）去set一个的操作并回设缓存；否则，就重试整个get缓存的方法。 ​ 2.设置热点数据永远不过期 缓存穿透​ 缓存穿透是指查询一个一定不存在的数据，由于缓存是不命中时被动写的，并且出于容错考虑，如果从存储层查不到数据则不写入缓存，这将导致这个不存在的数据每次请求都要到存储层去查询，失去了缓存的意义。在流量大时，可能DB就挂掉了，要是有人利用不存在的key频繁攻击我们的应用，这就是漏洞。 解决方案： 有很多种方法可以有效地解决缓存穿透问题， ​ 1.最常见的则是采用布隆过滤器，将所有可能存在的数据哈希到一个足够大的bitmap中，一个一定不存在的数据会被这个bitmap拦截掉，从而避免了对底层存储系统的查询压力。 ​ 2.另外也有一个更为简单粗暴的方法，如果一个查询返回的数据为空（不管是数据不存在，还是系统故障），我们仍然把这个空结果进行缓存，但它的过期时间会很短，最长不超过五分钟。 ​ 3.Nginx对单个IP每秒访问次数进行限制 一般避免以上情况发生我们从三个时间段去分析下： 事前：Redis 高可用，主从+哨兵，Redis cluster，避免全盘崩溃。 事中：本地 ehcache 缓存 + Hystrix 限流+降级，避免** MySQL** 被打死。 事后：Redis 持久化 RDB+AOF，一旦重启，自动从磁盘上加载数据，快速恢复缓存数据。 限流组件，可以设置每秒的请求，有多少能通过组件，剩余的未通过的请求，怎么办？走降级！可以返回一些默认的值，或者友情提示，或者空白的值。 好处： ​ 数据库绝对不会死，限流组件确保了每秒只有多少个请求能通过。 只要数据库不死，就是说，对用户来说，3/5 的请求都是可以被处理的。 只要有 3/5 的请求可以被处理，就意味着你的系统没死，对用户来说，可能就是点击几次刷不出来页面，但是多点几次，就可以刷出来一次。 ​ 这个在目前主流的互联网大厂里面是最常见的 参见：敖丙的系列","link":"/2019/11/26/redis-learning-3/"},{"title":"spring学习前瞻","text":"Spring 源码分析文章列表Ⅰ. IOC 更新时间 标题 2018-05-30 Spring IOC 容器源码分析系列文章导读 2018-06-01 Spring IOC 容器源码分析 - 获取单例 bean 2018-06-04 Spring IOC 容器源码分析 - 创建单例 bean 的过程 2018-06-06 Spring IOC 容器源码分析 - 创建原始 bean 对象 2018-06-08 Spring IOC 容器源码分析 - 循环依赖的解决办法 2018-06-11 Spring IOC 容器源码分析 - 填充属性到 bean 原始对象 2018-06-11 Spring IOC 容器源码分析 - 余下的初始化工作 Ⅱ. AOP 更新时间 标题 2018-06-17 Spring AOP 源码分析系列文章导读 2018-06-20 Spring AOP 源码分析 - 筛选合适的通知器 2018-06-20 Spring AOP 源码分析 - 创建代理对象 2018-06-22 Spring AOP 源码分析 - 拦截器链的执行过程 Ⅲ. MVC 更新时间 标题 2018-06-29 Spring MVC 原理探秘 - 一个请求的旅行过程 2018-06-30 Spring MVC 原理探秘 - 容器的创建过程 参见：coolblog.xyz作者：coolblog.xyz转自：博客：http://www.coolblog.xyz","link":"/2019/12/04/spring-pre/"},{"title":"LOG日志桥接关系","text":"这里思考几个问题： 1.日志框架是给Java应用提供的方便进行记录日志的，那为什么又不让在应用中直接使用其API呢？ 2.这里面推崇使用的SLF4J是什么呢？ 3.所谓的门面模式又是什么东西呢？ 4.它是怎么做到统一的呢？ 门面模式迪米特法则：talk only to your immediate friends 迪米特法则的[初衷](https://baike.baidu.com/item/初衷)在于降低类之间的[耦合](https://baike.baidu.com/item/耦合/2821124)。由于每个类尽量减少对其他类的依赖，因此，很容易使得系统的功能模块功能独立，相互之间不存在（或很少有）依赖关系。 迪米特法[友元类](https://baike.baidu.com/item/友元类/518734)转达。因此，应用迪米特法则有可能造成的一个后果就是：系统中存在大量的中介类，这些类之所以存在完全是为了传递类之间的相互调用关系这在一定程度上增加了系统的复杂度。 ​ 外观模式创造出一个外观对象，将客户端所涉及的属于一个子系统的协作伙伴的数量减到最少，使得客户端与子系统内部的对象的相互作用被外观对象所取代。外观类充当了客户类与子系统类之间的“第三者”，降低了客户类与子系统类之间的耦合度 更形象点： 优点: - 松耦合 用户与子系统解耦，屏蔽子系统；可以提高子系统的独立性； - 简单易用 简化用户与子系统的依赖关系； 用户只与门面对接，有统一的入口；不需要知道所有子系统及内部构造； - 更好的划分访问层次 有些方法是对系统外的，有些方法是系统内部相互交互的使用的。子系统把那些暴露给外部的功能集中到门面中，这样就可以实现客户端的使用，很好的隐藏了子系统内部的细节。 缺点: 不能很好地限制客户使用子系统类，如果对客户访问子系统类做太多的限制则减少了可变性和灵活性。 在不引入抽象外观类的情况下，增加新的子系统可能需要修改外观类或客户端的源代码，违背了“开闭原则”。开闭原则两个主要特征： （1）对于扩展是开放的（Open for extension）。 （2）对于修改是关闭的（Closed for modification）。 错误使用行为 不要通过继承一个外观类在子系统中加入新的行为，这种做法是错误的。 外观模式的用意是为子系统提供一个集中化和简化的沟通渠道，而不是向子系统加入新的行为，新的行为的增加应该通过修改原有子系统类或增加新的子系统类来实现，不能通过外观类来实现。Log日志框架关系 1996年早期，欧洲安全电子市场项目组决定编写它自己的程序跟踪API(Tracing API)。经过不断的完善，这个API终于成为一个十分受欢迎的Java日志软件包，即Log4j。后来Log4j成为Apache基金会项目中的一员。 期间Log4j近乎成了Java社区的日志标准。据说Apache基金会还曾经建议Sun引入Log4j到java的标准库中，但Sun拒绝了。 2002年Java1.4发布，Sun推出了自己的日志库JUL(Java Util Logging),其实现基本模仿了Log4j的实现。在JUL出来以前，Log4j就已经成为一项成熟的技术，使得Log4j在选择上占据了一定的优势。 接着，Apache推出了Jakarta Commons Logging，JCL只是定义了一套日志接口(其内部也提供一个Simple Log的简单实现)，支持运行时动态加载日志组件的实现，也就是说，在你应用代码里，只需调用Commons Logging的接口，底层实现可以是Log4j，也可以是Java Util Logging。 后来(2006年)，Ceki Gülcü离开了Apache。然后先后创建了Slf4j(日志门面接口，类似于Commons Logging)和Logback(Slf4j的实现)两个项目，并回瑞典创建了QOS公司，QOS官网上是这样描述Logback的：The Generic，Reliable Fast&amp;Flexible Logging Framework(一个通用，可靠，快速且灵活的日志框架)。从此以后，Java日志领域被划分为两大阵营：Commons Logging阵营和Slf4j阵营。 2012年，Apache重写了Log4j 1.x，成立了新的项目Log4j 2 Commons Logging和Slf4j是日志门面 Log4j和Logback则是具体的日志实现方案 这里可以看出分为三个层次： 抽象层：提供应用直接调用api 适配层：提供于抽象层和实现层的适配实现 实现层：api的实现 通过log4j-slf4j-impl来看是如何桥接 jar包名 说明 slf4j-log4j12-1.7.13.jar Log4j1.2版本的桥接器，你需要将Log4j.jar加入Classpath。 slf4j-jdk14-1.7.13.jar java.util.logging的桥接器，Jdk原生日志框架。 slf4j-nop-1.7.13.jar NOP桥接器，默默丢弃一切日志。 slf4j-simple-1.7.13.jar 一个简单实现的桥接器，该实现输出所有事件到System.err. 只有Info以及高于该级别的消息被打印，在小型应用中它也许是有用的。 slf4j-jcl-1.7.13.jar Jakarta Commons Logging 的桥接器. 这个桥接器将Slf4j所有日志委派给Jcl。 logback-classic-1.0.13.jar(requires logback-core-1.0.13.jar) Slf4j的原生实现，Logback直接实现了Slf4j的接口，因此使用Slf4j与Logback的结合使用也意味更小的内存与计算开销 如何将日志框架指向SLF4J： jar包名 作用 log4j-over-slf4j.jar 将Log4j 1重定向到Slf4j jcl-over-slf4j.jar 将Commons Logging里的Simple Logger重定向到slf4j jul-to-slf4j.jar 将Java Util Logging重定向到Slf4j log4j-to-slf4j log4j 2 API到slf4j的适配 Slf4j/log4j2集成举例 如果我们在系统中需要使用slf4j和log4j2来进行日志输出的话，我们需要引入下面的jar包： 123log4j2核心jar包：log4j-api-2.7.jar和log4j-core-2.7.jarslf4j核心jar包：slf4j-api-1.6.4.jarslf4j与log4j2的桥接包：log4j-slf4j-impl-2.7.jar，这个包的作用就是使用slf4j的api，但是底层实现是基于log4j2 死循环问题 多个日志jar包形成死循环的条件 产生原因 log4j-over-slf4j.jar和slf4j-log4j12.jar 由于slf4j-log4j12.jar的存在会将所有日志调用委托给log4j。但由于同时由于log4j-over-slf4j.jar的存在，会将所有对log4j api的调用委托给相应等值的slf4j,所以log4j-over-slf4j.jar和slf4j-log4j12.jar同时存在会形成死循环 jcl-over-slf4j 与 slf4j-jcl Jcl-over-slf4j : commons-logging切换到slf4j slf4j-jcl : slf4j切换到commons-logging jul-to-slf4j.jar和slf4j-jdk14.jar 由于slf4j-jdk14.jar的存在会将所有日志调用委托给jdk的log。但由于同时jul-to-slf4j.jar的存在，会将所有对jul api的调用委托给相应等值的slf4j，所以jul-to-slf4j.jar和slf4j-jdk14.jar同时存在会形成死循环 123死循环日志：SLF4J: Detected both log4j-over-slf4j.jar AND slf4j-log4j12.jar on the class path, preempting StackOverflowError. SLF4J: See also http://www.slf4j.org/codes.html#log4jDelegationLoop for more details. 看到这里，是不是很头大，这么多工具类，怎么管理这些包之间的关系，使得日志的使用情况和预期一致，并且规避日志引起的问题呢？ 日志依赖包管理方案方案1:采用maven的exclusion方案 优点是exclusion是maven原生提供的 不足之处是如果有多个组件都依赖了commons-logging，则需要在很多处增加，使用起来不太方便 方案2: 在maven声明commons-logging的scope为provided ​ 这种方案在调试代码时还是有可能导致IDE将commons-logging放置在classpath下，从而导致程序运行时出现异常 方案3:在maven私服中增加虚拟的版本号 【建议方案】 ​ 好处是声明方式比较简单，用IDE调试代码时也不会出现问题，不足之处是maven中央仓库中是不存在的，需要发布到自己的maven私服中。 ​ 但是，这种方式得注意，由于maven的加载关系，必须得把此配置声明放在顶级pom文件中，保证优先加载此空jar包 虚拟版本号原理 123Maven 解析 pom.xml 文件时，同一个 jar 包只会保留一个，这样有效的避免因引入两个 jar 包导致的工程运行不稳定性。 举例：假设 A-&gt;B-&gt;C-&gt;D1, E-&gt;F-&gt;D2，D1,D2 分别为 D 的不同版本。那么会引入哪个版本？ Maven 默认处理策略 最短路径优先 Maven 面对 D1 和 D2 时，会默认选择最短路径的那个 jar 包，即 D2。E-&gt;F-&gt;D2 比 A-&gt;B-&gt;C-&gt;D1 路径短 1。 最先声明优先 ​ 如果路径一样的话，举个： A-&gt;B-&gt;C1, E-&gt;F-&gt;C2 ，两个依赖路径长度都是 2，那么就选择最先声明。","link":"/2019/11/29/j2ee-log/"},{"title":"redis学习（二）","text":"参见：文章地址 Redis对象类型简介 Redis是一种key/value型数据库，其中，每个key和value都是使用对象表示的。比如，我们执行以下代码： 1redis＞ SET message &quot;hello redis&quot; 其中的key是message，是一个包含了字符串”message”的对象。而value是一个包含了”hello redis”的对象。Redis共有五种对象的类型，分别是： 类型常量 对象的名称 REDIS_STRING 字符串对象 REDIS_LIST 列表对象 REDIS_HASH 哈希对象 REDIS_SET 集合对象 REDIS_ZSET 有序集合对象 Redis中的一个对象的结构体表示如下： 123456789101112131415typedef struct redisObject { // 类型 unsigned type:4; // 编码方式 unsigned encoding: 4; // 引用计数 int refcount; // 指向对象的值 void *ptr; } robj; type表示了该对象的对象类型，即上面五个中的一个。但为了提高存储效率与程序执行效率，每种对象的底层数据结构实现都可能不止一种。encoding就表示了对象底层所使用的编码。 Redis对象底层数据结构 编码常量 编码所对应的底层数据结构 REDIS_ENCODING_INT long 类型的整数 REDIS_ENCODING_EMBSTR embstr 编码的简单动态字符串 REDIS_ENCODING_RAW 简单动态字符串 REDIS_ENCODING_HT 字典 REDIS_ENCODING_LINKEDLIST 双端链表 REDIS_ENCODING_ZIPLIST 压缩列表 REDIS_ENCODING_INTSET 整数集合 REDIS_ENCODING_SKIPLIST 跳跃表和字典 字符串对象 字符串对象的编码可以是int、raw或者embstr如果一个字符串的内容可以转换为long，那么该字符串就会被转换成为long类型，对象的ptr就会指向该long，并且对象类型也用int类型表示。普通的字符串有两种，embstr和raw。embstr应该是Redis 3.0新增的数据结构,在2.8中是没有的。如果字符串对象的长度小于39字节，就用embstr对象。否则用传统的raw对象。 1234567#define REDIS_ENCODING_EMBSTR_SIZE_LIMIT 44 robj *createStringObject(char *ptr, size_t len) { if (len &lt;= REDIS_ENCODING_EMBSTR_SIZE_LIMIT) return createEmbeddedStringObject(ptr,len); else return createRawStringObject(ptr,len); } embstr的好处有如下几点： embstr的创建只需分配一次内存，而raw为两次（一次为sds分配对象，另一次为objet分配对象，embstr省去了第一次）。 相对地，释放内存的次数也由两次变为一次。 embstr的objet和sds放在一起，更好地利用缓存带来的优势。 raw和embstr的区别可以用下面两幅图所示： 列表对象 列表对象的编码可以是ziplist或者linkedlist ziplist是一种压缩链表，它的好处是更能节省内存空间，因为它所存储的内容都是在连续的内存区域当中的。当列表对象元素不大，每个元素也不大的时候，就采用ziplist存储但当数据量过大时就ziplist就不是那么好用了。因为为了保证他存储内容在内存中的连续性，插入的复杂度是O(N)，即每次插入都会重新进行realloc。如下图所示，对象结构中ptr所指向的就是一个ziplist整个ziplist只需要malloc一次，它们在内存中是一块连续的区域。 linkedlist是一种双向链表。它的结构比较简单，节点中存放pre和next两个指针，还有节点相关的信息。当每增加一个node的时候，就需要重新malloc一块内存。 哈希对象 哈希对象的底层实现可以是ziplist或者hashtable。ziplist中的哈希对象是按照key1,value1,key2,value2这样的顺序存放来存储的。当对象数目不多且内容不大时，这种方式效率是很高的。 hashtable的是由dict这个结构来实现的, dict是一个字典，其中的指针dicht ht[2] 指向了两个哈希表 12345678910111213typedef struct dict { dictType *type; void *privdata; dictht ht[2]; long rehashidx; /* rehashing not in progress if rehashidx == -1 */ int iterators; /* number of iterators currently running */ } dict; typedef struct dictht { dictEntry **table; unsigned long size; unsigned long sizemask; unsigned long used; } dictht; dicht[0] 是用于真正存放数据，dicht[1]一般在哈希表元素过多进行rehash的时候用于中转数据。dictht中的table用语真正存放元素了，每个key/value对用一个dictEntry表示，放在dictEntry数组中。 集合对象 集合对象的编码可以是intset或者hashtableintset是一个整数集合，里面存的为某种同一类型的整数，支持如下三种长度的整数： 123#define INTSET_ENC_INT16 (sizeof(int16_t)) #define INTSET_ENC_INT32 (sizeof(int32_t)) #define INTSET_ENC_INT64 (sizeof(int64_t)) intset是一个有序集合，查找元素的复杂度为O(logN)，但插入时不一定为O(logN)，因为有可能涉及到升级操作。比如当集合里全是int16_t型的整数，这时要插入一个int32_t，那么为了维持集合中数据类型的一致，那么所有的数据都会被转换成int32_t类型，涉及到内存的重新分配，这时插入的复杂度就为O(N)了。intset不支持降级操作。 有序集合对象 有序集合的编码可能两种，一种是ziplist，另一种是skiplist与dict的结合。ziplist作为集合和作为哈希对象是一样的，member和score顺序存放。按照score从小到大顺序排列skiplist是一种跳跃表，它实现了有序集合中的快速查找，在大多数情况下它的速度都可以和平衡树差不多。但它的实现比较简单，可以作为平衡树的替代品。它的结构比较特殊。下面分别是跳跃表skiplist和它内部的节点skiplistNode的结构体： 123456789101112131415161718192021222324252627282930/* * 跳跃表 */ typedef struct zskiplist { // 头节点，尾节点 struct zskiplistNode *header, *tail; // 节点数量 unsigned long length; // 目前表内节点的最大层数 int level; } zskiplist; /* ZSETs use a specialized version of Skiplists */ /* * 跳跃表节点 */ typedef struct zskiplistNode { // member 对象 robj *obj; // 分值 double score; // 后退指针 struct zskiplistNode *backward; // 层 struct zskiplistLevel { // 前进指针 struct zskiplistNode *forward; // 这个层跨越的节点数量 unsigned int span; } level[]; } zskiplistNode; head和tail分别指向头节点和尾节点，然后每个skiplistNode里面的结构又是分层的(即level数组)用图表示，大概是下面这个样子： 总结以上简单介绍了Redis的简介，特性以及五种对象类型和五种对象类型的底层实现。事实上，Redis的高效性和灵活性正是得益于同一个对象类型采用不同的底层结构，并且在必要的时候对二者进行转换，还有就是各种底层结构对内存的合理利用。 本文作者：Worktile高级工程师 龚林杰 文章来源：Worktile技术博客","link":"/2019/11/26/redis-learning-2/"},{"title":"zookeeper学习前瞻","text":"ZK的由来12What is ZooKeeper? ZooKeeper is a centralized service for maintaining configuration information, naming, providing distributed synchronization, and providing group services. All of these kinds of services are used in some form or another by distributed applications. Each time they are implemented there is a lot of work that goes into fixing the bugs and race conditions that are inevitable. Because of the difficulty of implementing these kinds of services, applications initially usually skimp on them, which make them brittle in the presence of change and difficult to manage. Even when done correctly, different implementations of these services lead to management complexity when the applications are deployed. ​ Zookeeper 分布式服务框架是Apache Hadoop 的一个子项目，它主要是用来解决分布式应用中经常遇到的一些数据管理问题，如：统一命名服务、状态同步服务、集群管理、分布式应用配置项的管理等。 ​ Zookeeper 最早起源于雅虎研究院的一个研究小组。在当时，研究人员发现，在雅虎内部很多大型系统基本都需要依赖一个类似的系统来进行分布式协调，但是这些系统往往都存在分布式单点问题。 ​ 所以，雅虎的开发人员就试图开发一个通用的无单点问题的分布式协调框架，以便让开发人员将精力集中在处理业务逻辑上。 ​ 关于“ZooKeeper”这个项目的名字，其实也有一段趣闻。在立项初期，考虑到之前内部很多项目都是使用动物的名字来命名的（例如著名的Pig项目)，雅虎的工程师希望给这个项目也取一个动物的名字。 ​ 时任研究院的首席科学家 Raghu Ramakrishnan 开玩笑地说：“在这样下去，我们这儿就变成动物园了！” ​ 此话一出，大家纷纷表示就叫动物园管理员吧，因为各个以动物命名的分布式组件放在一起，雅虎的整个分布式系统看上去就像一个大型的动物园了。 ​ 而 Zookeeper 正好要用来进行分布式环境的协调，于是，Zookeeper 的名字也就由此诞生了。 ——《Paxos到 ZooKeeper 》 ZK的目标​ 将那些复杂且容易出错的分布式一致性服务封装起来，构成一个高效可靠的原语集，并以一系列简单易用的接口提供给用户使用。 原语： 操作系统或计算机网络用语范畴。它是由若干条指令组成的，用于完成一定功能的一个过程。具有不可分割性，即原语的执行必须是连续的，在执行过程中不允许被中断。 文件系统 123名称空间由 ZooKeeper 中的数据寄存器组成，称为 Znode，这些类似于文件和目录。与为存储设计的典型文件系统不同，ZooKeeper 数据保存在内存中，这意味着 ZooKeeper 可以实现高吞吐量和低延迟。 有四种类型的znode： 1、PERSISTENT-持久化目录节点 客户端与zookeeper断开连接后，该节点依旧存在 2、 PERSISTENT_SEQUENTIAL-持久化顺序编号目录节点 客户端与zookeeper断开连接后，该节点依旧存在，只是Zookeeper给该节点名称进行顺序编号 3、EPHEMERAL-临时目录节点 客户端与zookeeper断开连接后，该节点被删除 4、EPHEMERAL_SEQUENTIAL-临时顺序编号目录节点 客户端与zookeeper断开连接后，该节点被删除，只是Zookeeper给该节点名称进行顺序编号 通知机制 1Watcher （事件监听器） ： ZooKeeper 允许用户在指定节点上注册一些 Watcher，并且在一些特定事件触发的时候，ZooKeeper 服务端会将事件通知到感兴趣的客户端上去，该机制是 ZooKeeper 实现分布式协调服务的重要特性。 ZK的应用场景命名服务 在zookeeper的文件系统里创建一个目录，即有唯一的path。在我们无法确定上游程序的部署机器时即可与下游程序约定好path，通过path即能互相探索发现 配置管理 如果程序分散部署在多台机器上，要逐个改变配置就变得困难。好吧，现在把这些配置全部放到zookeeper上去，保存在 Zookeeper 的某个目录节点中，然后所有相关应用程序对这个目录节点进行监听，一旦配置信息发生变化，每个应用程序就会收到 Zookeeper 的通知，然后从 Zookeeper 获取新的配置信息应用到系统中就好。 集群管理 1.机器退出和加入 所有机器约定在父目录GroupMembers下创建临时目录节点，然后监听父目录节点的子节点变化消息。一旦有机器挂掉，该机器与 zookeeper的连接断开，其所创建的临时目录节点被删除，所有其他机器都收到通知。新机器加入 也是类似，所有机器收到通知 2.选举master 举个最简单的例子：所有机器创建临时顺序编号目录节点，每次选取编号最小的机器作为master 分布式锁 锁服务可以分为两类：一个是保持独占，另一个是控制时序。 独占锁：我们将zookeeper上的一个znode看作是一把锁，通过createznode的方式来实现。所有客户端都去创建 /distribute_lock 节点，最终成功创建的那个客户端也即拥有了这把锁。用完删除掉自己创建的distribute_lock 节点就释放出锁。 时序锁：预先创建 /distribute_lock 节点，所有客户端在它下面创建临时顺序编号目录节点，和选master一样，编号最小的获得锁，用完删除 队列管理 1.同步队列 ​ 当一个队列的成员都聚齐时，这个队列才可用，否则一直等待所有成员到达。 ​ 实现方案：在约定目录下创建临时目录节点，监听节点数目是否是我们要求的数目 2.FIFO 方式进行入队和出队操作 ​ 入列有编号，出列按编号 ZK可以实现的功能远远不止这些，这里只列出一些经典使用场景 ZK集群Master/Slave 模式（主备模式）: ​ 在这种模式中，通常 Master 服务器作为主服务器提供写服务，其他的 Slave 服务器从服务器通过异步复制的方式获取 Master 服务器最新的数据提供读服务。 角色 引入了Leader、Follower 和 Observer 三种角色。 1.Leader 既可以为客户端提供写服务又能提供读服务 2.Follower 和 Observer 都只能提供读服务 3.Follower 和 Observer 唯一的区别在于 Observer 机器不参与 Leader 的选举过程，也不参与写操作的“过半写成功”策略，因此 Observer 机器可以在不影响写性能的情况下提升集群的读性能 ZK一致性原理 ZK的一致性算法参照paxos算法实现，但不完全实现paxos算法。 ZAB 协议并不像 Paxos 算法那样，是一种通用的分布式一致性算法，它是一种特别为 ZooKeeper 设计的崩溃可恢复的原子消息广播算法。 ZAB（ZooKeeper Atomic Broadcast 原子广播）协议是为分布式协调服务 ZooKeeper 专门设计的一种支持崩溃恢复的原子广播协议。 ZAB 协议包括两种基本的模式，分别是崩溃恢复和消息广播。 当整个服务框架在启动过程中，或是当 Leader 服务器出现网络中断、崩溃退出与重启等异常情况时，ZAB 协议就会进入恢复模式并选举产生新的 Leader 服务器。 当选举产生了新的 Leader 服务器，同时集群中已经有过半的机器与该 Leader 服务器完成了状态同步之后，ZAB 协议就会退出恢复模式。 其中，所谓的状态同步是指数据同步，用来保证集群中存在过半的机器能够和 Leader 服务器的数据状态保持一致。 当集群中已经有过半的 Follower 服务器完成了和 Leader 服务器的状态同步，那么整个服务框架就可以进人消息广播模式了。 当一台同样遵守 ZAB 协议的服务器启动后加入到集群中时，如果此时集群中已经存在一个 Leader 服务器在负责进行消息广播。 那么新加入的服务器就会自觉地进人数据恢复模式：找到 Leader 所在的服务器，并与其进行数据同步，然后一起参与到消息广播流程中去。 请看下文paxos解读","link":"/2019/11/29/zk-pre/"},{"title":"zookeeper学习之Paxos协议","text":"拜占庭将军问题 拜占庭位于如今的土耳其的伊斯坦布尔，是东罗马帝国的首都。由于当时拜占庭罗马帝国国土辽阔，为了防御目的，因此每个军队都分隔很远，将军与将军之间只能靠信差传消息。在战争的时候，拜占庭军队内所有将军必需达成 一致的共识，决定是否有赢的机会才去攻打敌人的阵营。但是，在军队内有可能存有叛徒和敌军的间谍，左右将军们的决定又扰乱整体军队的秩序，在进行共识时，结果并不代表大多数人的意见。这时候，在已知有成员不可靠的情况下，其余忠诚的将军在不受叛徒或间谍的影响下如何达成一致的协议，拜占庭问题就此形成。 ​ 拜占庭假设是对现实世界的模型化，由于硬件错误、网络拥塞或断开以及遭到恶意攻击，计算机和网络可能出现不可预料的行为。 ​ 在常见的分布式系统中，总会发生诸如机器宕机或网络异常（包括消息的延迟、丢失、重复、乱序，还有网络分区）等情况。 ​ Paxos算法需要解决的问题就是如何在一个可能发生上述异常的分布式系统中，快速且正确地在集群内部对某个数据的值达成一致，并且保证不论发生以上任何异常，都不会破坏整个系统的一致性。 历史／趣事： “Leslie Lamport也是用了长达9年的时间来完善这个算法的理论”– •Lamport大牛在他Paxos的第一个版本早在1990年就提交给ACM TOCS Jnl.的评审委员会了,但是当时没有人理解他的算法 ,主编回执他的稿子建议他用数学而不是神话描述他的算法 他们才会考虑接受这篇paper 。 •Lamport大牛很生气 他有次就在一个会议上说:”为什么搞理论的这群人一点幽默感也没有呢?”, 他拒绝修改 而且withdraw了这篇文章。 •1996年微软的Butler Lampson在WDAG96上提出了重新审视这篇文章 因为他读懂了 •1997年MIT的Nancy Lynch在WDAG97上 根据原文重新改写了这篇文章，Lamport用数学形式化的定义并证明了Paxos。 •于是在1998年的ACM TOCS上 这篇迟到了9年的paper终于被接受了。 •后来2001年 Lamport大牛也作出了让步 他用简单的语言而不是神话故事 重述了原文 ，但是通篇还是没有数学符号， L大牛甚为固执 ，据他自己说 ，他检查过了自己的语言并没有歧义 ，不需要数学来描述。 Google Chubby的作者说：“这个世界上只有一种一致性算法，那就是 （Paxos 时间线： [1]. LESLIE LAMPORT, ROBERT SHOSTAK, MARSHALL PEASE. The Byzantine General Problem. 1982 [2]. Leslie Lamport. The Part-Time Parliament. 1998 [3]. Leslie Lamport. Paxos Made Simple. 2001 [4]. Diego Ongaro and John Ousterhout. Raft Paper. 2013 [5]. Raft Website. The Raft Consensus Algorithm [6]. Raft Demo. Raft Animate Demo Paxos共识算法 ​ Paxos本来是虚构故事中的一个小岛，议会通过表决来达成共识。但是议员可能离开，信使可能走丢，或者重复传递消息。对应到分布式系统的节点故障和网络故障。 •假设议员要提议中午吃什么。如果有一个或者多个人同时提议，但一次只能通过一个提议，这就是Basic Paxos，是Paxos中最基础的协议。 •显然Basic Paxos是不够高效的，如果将Basic Paxos并行起来，同时提出多个提议，比如中午吃什么、吃完去哪里嗨皮、谁请客等提议，议员也可以同时通过多个提议。这就是Multi-Paxos协议。 Basic Paxos角色 Paxos算法存在3种角色：Proposer、Acceptor、Learner，在实现中一个节点可以担任多个角色。 •Proposer负责提出提案 •Acceptor负责对提案进行投票 •Learner获取投票结果，并帮忙传播 Learner不参与投票过程，为了简化描述，我们直接忽略掉这个角色。 算法 运行过程分为两个阶段 •Prepare阶段 •Accept阶段 •Proposer需要发出两次请求，Prepare请求和Accept请求。 •Acceptor根据其收集的信息，接受或者拒绝提案。 Prepare阶段 •Proposer选择一个提案编号n，发送Prepare(n)请求给超过半数（或更多）的Acceptor。 •Acceptor收到消息后，如果n比它之前见过的编号大，就回复这个消息，而且以后不会接受小于n的提案。另外，如果之前已经接受了小于n的提案，回复那个提案编号和内容给Proposer。 Accept阶段 •当Proposer收到超过半数的回复时，就可以发送Accept(n, value)请求了。 n就是自己的提案编号，value是Acceptor回复的最大提案编号对应的value，如果Acceptor没有回复任何提案，value就是Proposer自己的提案内容。 •Acceptor收到消息后，如果n大于等于之前见过的最大编号，就记录这个提案编号和内容，回复请求表示接受。 •当Proposer收到超过半数的回复时，说明自己的提案已经被接受。否则回到第一步重新发起提案。 共识过程情况1：提案已接受 •这个过程表示，S1收到客户端的提案X，于是S1作为Proposer，给S1-S3发送Prepare(3.1)请求，由于Acceptor S1-S3没有接受过任何提案，所以接受该提案。然后Proposer S1-S3发送Accept(3.1, X)请求，提案X成功被接受。 •在提案X被接受后，S5收到客户端的提案Y，S5给S3-S5发送Prepare(4.5)请求。对S3来说，4.5比3.1大，且已经接受了X，它会回复这个提案 (3.1, X)。S5收到S3-S5的回复后，使用X替换自己的Y，于是发送Accept(4.5, X)请求。S3-S5接受提案。最终所有Acceptor达成一致，都拥有相同的值X。 •这种情况的结果是：新**Proposer**会使用已接受的提案 情况2：提案未接受，新Proposer可见 •S3接受了提案(3.1, X)，但S1-S2还没有收到请求。此时S3-S5收到Prepare(4.5)，S3会回复已经接受的提案(3.1, X)，S5将提案值Y替换成X，发送Accept(4.5, X)给S3-S5，对S3来说，编号4.5大于3.1，所以会接受这个提案。 •然后S1-S2接受Accept(3.1, X)，最终所有Acceptor达成一致。 •这种情况的结果是：新Proposer会使用已提交的值，两个提案都能成功 情况3： 提案未接受，新Proposer不可见 •S1接受了提案(3.1, X)，S3先收到Prepare(4.5)，后收到Accept(3.1, X)，由于3.1小于4.5，会直接拒绝这个提案。所以提案X无法收到超过半数的回复，这个提案就被阻止了。提案Y可以顺利通过。 •这种情况的结果是：新Proposer使用自己的提案，旧提案被阻止 活锁 •活锁发生的几率很小，但是会严重影响性能。就是两个或者多个Proposer在Prepare阶段发生互相抢占的情形。 •解决方案是Proposer失败之后给一个随机的等待时间，这样就减少同时请求的可能。 Multi-Paxos •它会从Proposer中选出一个Leader，只由Leader提交Proposal，还可以省去Prepare阶段，减少了性能损失。当然，直接把Basic Paxos的多个Proposer的机制搬过来也是可以的，只是性能不够高。 •将Basic Paxos并行之后，就可以同时处理多个提案了，因此要能存储不同的提案，也要保证提案的顺序。 上文提到的活锁，也可以使用Multi-Paxos来解决 Multi-Paxos需要解决的问题 1. Leader选举 •一个最简单的选举方法，就是Server ID最大的当Leader。 •每个Server间隔T时间向其他Server发送心跳包，如果一个Server在2T时间内没有收到来自更高ID的心跳，那么它就成为Leader。 •其他Proposer，必须拒绝客户端的请求，或将请求转发给Leader。 •当然，还可以使用其他更复杂的选举方法，这里不再详述。 2.省略Prepare阶段 •Prepare的作用是阻止旧的提案，以及检查是否有已接受的提案值。 •当只有一个Leader发送提案的时候，Prepare是不会产生冲突的，可以省略Prepare阶段，这样就可以减少一半RPC请求。 •Prepare请求的逻辑修改为： –Acceptor记录一个全局的最大提案编号 –回复最大提案编号，如果当前entry以及之后的所有entry都没有接受任何提案，回复noMoreAccepted –当Leader收到超过半数的noMoreAccepted回复，之后就不需要Prepare阶段了，只需要发送Accept请求。直到Accept被拒绝，就重新需要Prepare阶段。 3. 完整信息流 •Basic Paxos只需超过半数的节点达成一致。但是在Multi-Paxos中，这种方式可能会使一些节点无法得到完整的entry信息。我们希望每个节点都拥有全部的信息。 •只有Proposer知道一个提案是否被接受了（根据收到的回复），而Acceptor无法得知此信息。 第1个问题的解决方案很简单，就是Proposer给全部节点发送Accept请求。 第2个问题稍微复杂一些。首先，我们可以增加一个Success RPC，让Proposer显式地告诉Acceptor，哪个提案已经被接受了，这个是完全可行的，只不过还可以优化一下，减少请求次数。 优化策略 在Accept请求中，增加一个firstUnchosenIndex参数，表示Proposer的第一个未接受的Index，这个参数隐含的意思是，对该Proposer来说，小于Index的提案都已经被接受了。因此Acceptor可以利用这个信息，把小于Index的提案标记为已接受。 另外要注意的是，只能标记该Proposer的提案，因为如果发生Leader切换，不同的Proposer拥有的信息可能不同，不区分Proposer直接标记的话可能会不一致。 Proposer正在准备提交Index=2的Accept请求，0和1是已接受的提案，因此firstUnchosenIndex=2。当Acceptor收到请求后，比较Index，就可以将Dumplings提案标记为已接受。 由于之前提到的Leader切换的情况，仍然需要显式请求才能获得完整信息。在Acceptor回复Accept消息时，带上自己的firstUnchosenIndex。如果比Proposer的小，那么就需要发送Success(index, value)，Acceptor将收到的index标记为已接受，再回复新的firstUnchosenIndex，如此往复直到两者的index相等。 这篇文章的分析来源于网络，具体没有记录来源，如有侵权，请联系我删除，谢谢！","link":"/2019/11/29/zk-paxos/"}],"tags":[{"name":"算法","slug":"算法","link":"/tags/%E7%AE%97%E6%B3%95/"},{"name":"DUBBO","slug":"DUBBO","link":"/tags/DUBBO/"},{"name":"MOCK","slug":"MOCK","link":"/tags/MOCK/"},{"name":"LINUX","slug":"LINUX","link":"/tags/LINUX/"},{"name":"I/O","slug":"I-O","link":"/tags/I-O/"},{"name":"HTTP","slug":"HTTP","link":"/tags/HTTP/"},{"name":"JVM","slug":"JVM","link":"/tags/JVM/"},{"name":"linux ","slug":"linux","link":"/tags/linux/"},{"name":"MQ","slug":"MQ","link":"/tags/MQ/"},{"name":"MYSQL","slug":"MYSQL","link":"/tags/MYSQL/"},{"name":"REDIS","slug":"REDIS","link":"/tags/REDIS/"},{"name":"SPRING","slug":"SPRING","link":"/tags/SPRING/"},{"name":"J2EE","slug":"J2EE","link":"/tags/J2EE/"},{"name":"LOG","slug":"LOG","link":"/tags/LOG/"},{"name":"设计模式","slug":"设计模式","link":"/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"name":"ZK","slug":"ZK","link":"/tags/ZK/"}],"categories":[]}